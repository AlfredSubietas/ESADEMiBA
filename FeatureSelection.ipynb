{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "#sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "The element that has the biggest impact in the quality of your model is data features. You can only include in your model the attributes that you have and if they are not relevant, partially relevant or don't caputre the causality relationships behind the model, or introduce other relationships that correspond to other causes different from the ones that you want to investigate, then you'll have a poor model. \n",
    "\n",
    "Selecting the relevant features that add to your model is therefore of the utmost importance. \n",
    "\n",
    "In this notebook we will deal with four approaches:\n",
    "\n",
    "        1) Univariate Selection.\n",
    "        2) Recursive feature elimination.\n",
    "        3) PCA - Principal Component Analysis.\n",
    "        4) Estimating feature importance.\n",
    "\n",
    "Feature selection is a process where you select those features in your data that contribute most to the variable of interest. Irrelevant features decrease the accuracy of many models because you try to adjust on noise, this is particularly important in the case of linear models, such as linear and logistic regressions, where all features are always taken into accout. Three are the main benefits of feature selection:\n",
    "\n",
    "        1) Reduces overfitting. Less redundant data implies less decisions made on noise. \n",
    "        2) Improves accuracy. Less misleading data results in a more accurate model. \n",
    "        3) Reduces training time. Less data implies faster training. \n",
    "        \n",
    "Scikitlearn has a nice and short article on feature selection where you can learn more https://scikit-learn.org/stable/modules/feature_selection.html\n",
    "\n",
    "Again we will use the Pima Indians onset of diabetes dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yo: (which ost important features, except PCA)\n",
    "UNIVARIATE: try to learn which feature is the most important one. But every model has a bias. Bias are not necessarily bad. so not so much overfitting. \n",
    "RECURSIVE: you take any model. e.g. you have 4 attributes, build the model with another combination of 3 and exhaust all the combinations. and then you rank accuracy. from that you can estimate the importance of that attribute. this is good because it realtes to a model. you are testing it with the model, it is not a theoretical thing. It is like this. Problem: you use more computational power. But it is real. Of course, it changes if you use another model. Is model-related.\n",
    "One feature out and you try and with that you see the behaviour. And rank. without this attribute accuracy was X, while the other was Y. But computational power not so important today.\n",
    "PCA: comes from statistic. is a completely differrent thing from the other three. you don't try to see the most relevant one. you. Reduce complexity. You create a matrix and eigenvalues... less dimensions. Theses dimensions are made of other ones. They are just combinations of things. Difficult to explain in real life. But many times no attribute dominates so difficult to explain. If you just carea about accuracy, fits very well the model. But not a good way to go for interpretation. New dimensions don't mean anything. (XGBoost does this for you?)\n",
    "ESTIMATING: no bias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Pima_indians_cowboy_1889.jpg\">\n",
    "\n",
    "In this exercise we will use one of the traditional Machine Learning dataset, the Pima Indians diabetes dataset.\n",
    "\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "Content\n",
    "The datasets consists of several medical predictor variables and one target variable, <b>Outcome</b>. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n",
    "<blockquote>\n",
    "        <ul style=\"list-style-type:square;\">\n",
    "            <li>Pregnancies</li> \n",
    "            <li>Glucose</li>\n",
    "            <li>BloodPressure</li>\n",
    "            <li>SkinThickness</li>\n",
    "            <li>Insulin</li>\n",
    "            <li>BMI</li>\n",
    "            <li>DiabetesPedigreeFunction (scores de likelihood of diabetes based on family history)</li>\n",
    "            <li>Age</li>\n",
    "            <li>Outcome</li>\n",
    "        </ul>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1     2     3      4     5      6     7\n",
       "0  6.0  148.0  72.0  35.0    0.0  33.6  0.627  50.0\n",
       "1  1.0   85.0  66.0  29.0    0.0  26.6  0.351  31.0\n",
       "2  8.0  183.0  64.0   0.0    0.0  23.3  0.672  32.0\n",
       "3  1.0   89.0  66.0  23.0   94.0  28.1  0.167  21.0\n",
       "4  0.0  137.0  40.0  35.0  168.0  43.1  2.288  33.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Pima indians dataset and separate input and output components \n",
    "\n",
    "from numpy import set_printoptions\n",
    "set_printoptions(precision=3)\n",
    "\n",
    "filename=\"pima-indians-diabetes.data.csv\"\n",
    "names=[\"pregnancies\", \"glucose\", \"pressure\", \"skin\", \"insulin\", \"bmi\", \"pedi\", \"age\", \"outcome\"]\n",
    "p_indians=pd.read_csv(filename, names=names)\n",
    "p_indians.head()\n",
    "\n",
    "# First we separate into input and output components\n",
    "array=p_indians.values\n",
    "X=array[:,0:8]\n",
    "Y=array[:,8]\n",
    "X\n",
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Univariate Selection </h1>\n",
    "\n",
    "One approach is to use statistical tests for example the Pearson Chi-Squared $\\chi^2$ is commonly used to select the most significant features. \n",
    "\n",
    "We will use the <b> SelectKBest </b> class in scikit-learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 111.52 , 1411.887,   17.605,   53.108, 2175.565,  127.669,\n",
       "          5.393,  181.304])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 4 attributes with the highest scores are: glucose, insulin, bmi and age \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[148. ,   0. ,  33.6,  50. ],\n",
       "       [ 85. ,   0. ,  26.6,  31. ],\n",
       "       [183. ,   0. ,  23.3,  32. ],\n",
       "       [ 89. ,  94. ,  28.1,  21. ],\n",
       "       [137. , 168. ,  43.1,  33. ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Univariate selection using Chi-squared \n",
    "set_printoptions(precision=3)\n",
    "p_indians.head()\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2 \n",
    "\n",
    "# feature selection (we select the 4 best)\n",
    "test = SelectKBest(score_func=chi2, k=4) #selecciona los mejores, la metodología siendo chi2 y seleccionando 4\n",
    "fit = test.fit(X,Y)\n",
    "print(\"Scores\")\n",
    "\n",
    "fit.scores_\n",
    "\n",
    "print(\"The 4 attributes with the highest scores are: glucose, insulin, bmi and age \")\n",
    "print()\n",
    "\n",
    "features=fit.transform(X)\n",
    "features[0:5,:]\n",
    "\n",
    "# en el transform solo elimina las colunmnas.\n",
    "\n",
    "# miras variabilidad explicada por chi2 de cada una de las variables y te quedas con el mayor valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Recursive Feature Elimination</h1>\n",
    "\n",
    "This is a very intuitive approach. It consist on recursively removing attributes and building a model with those atrributes remaining. It uses the model accuracy to identify which atrributes or combination of attributes contribute the most. \n",
    "\n",
    "We will use it with a logistic regression, but the choice of algorithm doesn't matter too much as long as your are consistent. \n",
    "\n",
    "Recursive Feature Elimination uses the <b>RFE </b> class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features 3\n",
      "Selected features [ True False False False False  True  True False]\n",
      "Ranking of features [1 2 3 5 6 1 1 4]\n",
      "\n",
      "Top features seem to be pregnancies, bmi, and pedi(Diabetes Pedigree Function)\n"
     ]
    }
   ],
   "source": [
    "# Recursive Feature Elimiantion\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression # el modelo del training, no de feature selection.\n",
    "\n",
    "p_indians.head()\n",
    "\n",
    "#Logistic regression\n",
    "model = LogisticRegression(solver='liblinear') \n",
    "\n",
    "#A:es model-related. Buscar el mejor modelo es exploration.\n",
    "#does not overfit as much, esa es la ventaja.\n",
    "\n",
    "rfe = RFE(model, 3) #  we want to find the 3 top features\n",
    "fit = rfe.fit(X, Y)\n",
    "\n",
    "print(f'Number of features {fit.n_features_:d}')\n",
    "print(f'Selected features {fit.support_}')\n",
    "print(f'Ranking of features {fit.ranking_}')\n",
    "print()\n",
    "print(\"Top features seem to be pregnancies, bmi, and pedi(Diabetes Pedigree Function)\")\n",
    "\n",
    "#los resultados son completamente diferentes a lo que obteníamos antes.\n",
    "#esto es real. You test it.\n",
    "#rfe is real\n",
    "#classification, you look for accuracy, is the normal thing.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# A:\n",
    "# Coges todas las variables y vas quitando y viendo cómo afecta a la varianza que explicas.\n",
    "# Está usando los coeficientes obtenidos en el fit del modelo que le he dado para saber qué tiene que eliminar.\n",
    "# Hace algo similar a penalizar los coeficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"red\" size=6>Mission 1</font>\n",
    "\n",
    "For this and the next mission we will use data from Kaggle In concrete from the World University Rankings Competition https://www.kaggle.com/mylesoneill/world-university-rankings\n",
    "\n",
    "a) Using the Shanghai rankings find the top 3 most important features to explain them with both univariate and recursive (in recursive because we are using log regression create an output variable of being in the top 50 or not).\n",
    "<br><br>\n",
    "b) Same for the Times ranking. \n",
    "<br><br>\n",
    "c) Does it change if we choose the top 10 or top 100?\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world_rank</th>\n",
       "      <th>university_name</th>\n",
       "      <th>alumni</th>\n",
       "      <th>award</th>\n",
       "      <th>hici</th>\n",
       "      <th>ns</th>\n",
       "      <th>pub</th>\n",
       "      <th>pcp</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>72.4</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>99.8</td>\n",
       "      <td>93.4</td>\n",
       "      <td>53.3</td>\n",
       "      <td>56.6</td>\n",
       "      <td>70.9</td>\n",
       "      <td>66.9</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>41.1</td>\n",
       "      <td>72.2</td>\n",
       "      <td>88.5</td>\n",
       "      <td>70.9</td>\n",
       "      <td>72.3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>University of California, Berkeley</td>\n",
       "      <td>71.8</td>\n",
       "      <td>76.0</td>\n",
       "      <td>69.4</td>\n",
       "      <td>73.9</td>\n",
       "      <td>72.2</td>\n",
       "      <td>52.7</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Massachusetts Institute of Technology (MIT)</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.6</td>\n",
       "      <td>66.7</td>\n",
       "      <td>65.8</td>\n",
       "      <td>64.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   world_rank                              university_name  alumni  award  \\\n",
       "0         1.0                           Harvard University   100.0  100.0   \n",
       "1         2.0                      University of Cambridge    99.8   93.4   \n",
       "2         3.0                          Stanford University    41.1   72.2   \n",
       "3         4.0           University of California, Berkeley    71.8   76.0   \n",
       "4         5.0  Massachusetts Institute of Technology (MIT)    74.0   80.6   \n",
       "\n",
       "    hici     ns    pub   pcp  year  \n",
       "0  100.0  100.0  100.0  72.4  2005  \n",
       "1   53.3   56.6   70.9  66.9  2005  \n",
       "2   88.5   70.9   72.3  65.0  2005  \n",
       "3   69.4   73.9   72.2  52.7  2005  \n",
       "4   66.7   65.8   64.3  53.0  2005  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Univariate ------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 75443.056, 123638.503,  51511.303,  42133.099,  15032.945,\n",
       "        14897.774])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[100. , 100. , 100. ],\n",
       "       [ 99.8,  93.4,  53.3],\n",
       "       [ 41.1,  72.2,  88.5],\n",
       "       ...,\n",
       "       [ 13.6,   0. ,   3.6],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,  14.9]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(123638.50331046723, 'award'),\n",
       " (75443.05612636959, 'alumni'),\n",
       " (51511.303069663074, 'hici')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected features are: ['award', 'alumni', 'hici']\n",
      "------ Recursive ------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True, False, False])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[100. , 100. , 100. ],\n",
       "       [ 93.4,  53.3,  56.6],\n",
       "       [ 72.2,  88.5,  70.9],\n",
       "       ...,\n",
       "       [  0. ,   3.6,  10.8],\n",
       "       [  0. ,   0. ,  12.2],\n",
       "       [  0. ,  14.9,   7.5]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected features are: ['ns', 'hici', 'award']\n"
     ]
    }
   ],
   "source": [
    "# A) Using the Shanghai rankings find the top 3 most important features to explain them with both univariate and recursive \n",
    "# (in recursive because we are using log regression create an output variable of being in the top 50 or not).\n",
    "\n",
    "# Import dataset\n",
    "sg_data = pd.read_csv('shanghaiData.csv')\n",
    "sg_data['world_rank'] = sg_data['world_rank'].str.split('-').str.get(0).astype(float)\n",
    "sg_data.drop(columns=['national_rank','total_score'], inplace=True)\n",
    "sg_data.dropna(inplace=True)\n",
    "sg_data.head()\n",
    "\n",
    "    # 'world_rank' series presents several anomalies in 101-152 onwards, therefore the need to change that and convert to float.\n",
    "    # Eliminate attributes that are not necessary: 'national_rank' and 'total_score'\n",
    "    # Get rid of null values\n",
    "    \n",
    "# Select input and target variables with iloc (integer position-based) and transform to numpy arrays.\n",
    "# I do not select university_name and year as input variables.\n",
    "X = sg_data.iloc[:,2:8].values\n",
    "Y = sg_data.iloc[:,0:1].values\n",
    "\n",
    "\n",
    "print('------ Univariate ------')\n",
    "\n",
    "# Imports\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Select 3 most important features\n",
    "test = SelectKBest(score_func=chi2, k=3)\n",
    "fit = test.fit(X,Y)\n",
    "fit.scores_\n",
    "features = fit.transform(X)\n",
    "features\n",
    "\n",
    "# Show the results in a meaningful manner.\n",
    "results = sorted(zip(fit.scores_, sg_data.iloc[:,2:8].columns),reverse=True)[:3]\n",
    "results\n",
    "\n",
    "    # reverse: sort in Descending order.\n",
    "    # .columns: get the labels of the df.\n",
    "    # show only first three\n",
    "print('The selected features are: '+ str([x[1] for x in results]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('------ Recursive ------')\n",
    "\n",
    "# Imports\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Top50, since using log regression need for classification. And converting it into array.\n",
    "sg_data['Top50'] = sg_data['world_rank']<51\n",
    "Y = sg_data['Top50'].values\n",
    "\n",
    "# Select the 3 most important features.\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(X, Y)\n",
    "fit.support_  # show selected features\n",
    "\n",
    "# ¿HACE FALTA ESTO?\n",
    "features = fit.transform(X)\n",
    "features\n",
    "\n",
    "# Show results\n",
    "results = sorted(zip(fit.support_, sg_data.iloc[:,2:8].columns),reverse=True)[:3]\n",
    "print('The selected features are: '+ str([x[1] for x in results]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world_rank</th>\n",
       "      <th>university_name</th>\n",
       "      <th>country</th>\n",
       "      <th>teaching</th>\n",
       "      <th>international</th>\n",
       "      <th>research</th>\n",
       "      <th>citations</th>\n",
       "      <th>income</th>\n",
       "      <th>num_students</th>\n",
       "      <th>student_staff_ratio</th>\n",
       "      <th>international_students</th>\n",
       "      <th>female_male_ratio</th>\n",
       "      <th>year</th>\n",
       "      <th>females</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>California Institute of Technology</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>97.7</td>\n",
       "      <td>54.6</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>83.7</td>\n",
       "      <td>2243.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.27</td>\n",
       "      <td>33 : 67</td>\n",
       "      <td>2011</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>97.8</td>\n",
       "      <td>82.3</td>\n",
       "      <td>91.4</td>\n",
       "      <td>99.9</td>\n",
       "      <td>87.5</td>\n",
       "      <td>11074.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>37 : 63</td>\n",
       "      <td>2011</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>98.3</td>\n",
       "      <td>29.5</td>\n",
       "      <td>98.1</td>\n",
       "      <td>99.2</td>\n",
       "      <td>64.3</td>\n",
       "      <td>15596.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.22</td>\n",
       "      <td>42 : 58</td>\n",
       "      <td>2011</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>90.5</td>\n",
       "      <td>77.7</td>\n",
       "      <td>94.1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>18812.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>46 : 54</td>\n",
       "      <td>2011</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>University of Oxford</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>88.2</td>\n",
       "      <td>77.2</td>\n",
       "      <td>93.9</td>\n",
       "      <td>95.1</td>\n",
       "      <td>73.5</td>\n",
       "      <td>19919.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.34</td>\n",
       "      <td>46 : 54</td>\n",
       "      <td>2011</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   world_rank                        university_name  \\\n",
       "1         2.0     California Institute of Technology   \n",
       "2         3.0  Massachusetts Institute of Technology   \n",
       "3         4.0                    Stanford University   \n",
       "5         6.0                University of Cambridge   \n",
       "6         6.0                   University of Oxford   \n",
       "\n",
       "                    country  teaching  international  research  citations  \\\n",
       "1  United States of America      97.7           54.6      98.0       99.9   \n",
       "2  United States of America      97.8           82.3      91.4       99.9   \n",
       "3  United States of America      98.3           29.5      98.1       99.2   \n",
       "5            United Kingdom      90.5           77.7      94.1       94.0   \n",
       "6            United Kingdom      88.2           77.2      93.9       95.1   \n",
       "\n",
       "   income  num_students  student_staff_ratio  international_students  \\\n",
       "1    83.7        2243.0                  6.9                    0.27   \n",
       "2    87.5       11074.0                  9.0                    0.33   \n",
       "3    64.3       15596.0                  7.8                    0.22   \n",
       "5    57.0       18812.0                 11.8                    0.34   \n",
       "6    73.5       19919.0                 11.6                    0.34   \n",
       "\n",
       "  female_male_ratio  year  females  \n",
       "1           33 : 67  2011     33.0  \n",
       "2           37 : 63  2011     37.0  \n",
       "3           42 : 58  2011     42.0  \n",
       "5           46 : 54  2011     46.0  \n",
       "6           46 : 54  2011     46.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Univariate ------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.412e+04, 5.210e+03, 2.249e+04, 1.364e+04, 4.396e+03, 1.948e+06,\n",
       "       1.962e+03, 4.587e+01, 5.467e+02])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[9.770e+01, 9.800e+01, 2.243e+03],\n",
       "       [9.780e+01, 9.140e+01, 1.107e+04],\n",
       "       [9.830e+01, 9.810e+01, 1.560e+04],\n",
       "       ...,\n",
       "       [1.450e+01, 7.600e+00, 3.127e+04],\n",
       "       [2.010e+01, 1.600e+01, 1.012e+04],\n",
       "       [1.620e+01, 1.830e+01, 8.663e+03]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected features are: ['num_students', 'research', 'teaching']\n",
      "------ Recursive ------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False,  True,  True, False, False, False,  True, False])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[9.80e+01, 9.99e+01, 2.70e-01],\n",
       "       [9.14e+01, 9.99e+01, 3.30e-01],\n",
       "       [9.81e+01, 9.92e+01, 2.20e-01],\n",
       "       ...,\n",
       "       [7.60e+00, 1.93e+01, 2.00e-02],\n",
       "       [1.60e+01, 1.35e+01, 8.00e-02],\n",
       "       [1.83e+01, 2.86e+01, 4.00e-02]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected features are: ['research', 'international_students', 'citations']\n"
     ]
    }
   ],
   "source": [
    "# B) Same for the Times ranking. \n",
    "\n",
    "# Import dataset and do corresponding adjustments.\n",
    "times = pd.read_csv('timesData.csv')\n",
    "times.world_rank.replace('=.','.', regex=True, inplace=True)\n",
    "times['world_rank'] = times['world_rank'].str.split('-').str.get(0).astype(float)\n",
    "times.world_rank = pd.to_numeric(times.world_rank, errors='coerce')\n",
    "times.dropna(subset=['world_rank'], axis=0, inplace=True) # ??????????\n",
    "times.international = pd.to_numeric(times.international, errors='coerce')\n",
    "times.income = pd.to_numeric(times.income, errors='coerce')\n",
    "times.num_students.replace('\\D','', regex=True, inplace=True)\n",
    "times.num_students = pd.to_numeric(times.num_students, errors='coerce')\n",
    "times.international_students.replace('\\D','', regex=True, inplace=True)\n",
    "times.international_students = pd.to_numeric(times.international_students, errors='coerce')\n",
    "times.international_students = times.international_students/100\n",
    "times['females'] = times.female_male_ratio.str.split(':').str.get(0) # ¿alguna forma mejor?\n",
    "times.females = pd.to_numeric(times.females, errors='coerce')\n",
    "times.drop(columns='total_score',inplace=True)\n",
    "times.dropna(inplace=True)\n",
    "times.head()\n",
    "\n",
    "    # regex: bool or same types as to_replace, default False\n",
    "    #... Whether to interpret to_replace and/or value as regular expressions. If this is True then to_replace must be a string. \n",
    "    #...Alternatively,this could be a regular expression or a list, dict, or array of regular expressions \n",
    "    #...in which case to_replace must be None.\n",
    "    #... Second, if regex=True then all of the strings in both lists will be interpreted as regexs.\n",
    "    \n",
    "    #pd.to_numeric: convert argument to a numeric type.\\ If ‘coerce’, then invalid parsing will be set as NaN\n",
    "    \n",
    "    # dropna: subset: Labels along other axis to consider, \n",
    "    # e.g. if you are dropping rows these would be a list of columns to include.\n",
    "    #... axis : {0 or ‘index’, 1 or ‘columns’}\n",
    "    \n",
    "\n",
    "print('------ Univariate ------')\n",
    "\n",
    "# Select input and target variables with iloc (integer position-based) and transform to numpy arrays.\n",
    "X = pd.concat([times.iloc[:,3:11],times['females']],axis=1).values\n",
    "Y = times.iloc[:,0:1].values\n",
    "    #pandas.concat : Concatenate pandas objects along a particular axis with optional set logic along the other axes.\n",
    "    \n",
    "# Specific imports\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Select the 3 most important features.\n",
    "test = SelectKBest(score_func=chi2, k=3)\n",
    "fit = test.fit(X,Y.astype(int)) # convert float to integer, otherwise gives back error in this case!!\n",
    "fit.scores_\n",
    "features = fit.transform(X)\n",
    "features\n",
    "\n",
    "# Show in a meaningful manner\n",
    "results = sorted(zip(fit.scores_, pd.concat([times.iloc[:,3:11],times['females']],axis=1).columns),reverse=True)[:3]\n",
    "print('The selected features are: '+ str([x[1] for x in results]))\n",
    "\n",
    "\n",
    "\n",
    "print('------ Recursive ------')\n",
    "\n",
    "# Specific imports\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Select target variable and convert it to array\n",
    "times['Top50'] = times['world_rank']<51\n",
    "Y = times['Top50'].values\n",
    "\n",
    "# Select the 3 most important features.\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(X, Y)\n",
    "fit.support_\n",
    "features = fit.transform(X)\n",
    "features\n",
    "\n",
    "# Show in a meaningful manner\n",
    "results = sorted(zip(fit.support_, pd.concat([times.iloc[:,3:11],times['females']],axis=1).columns),reverse=True)[:3]\n",
    "print('The selected features are: '+ str([x[1] for x in results]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Shanghai10 ------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world_rank</th>\n",
       "      <th>university_name</th>\n",
       "      <th>alumni</th>\n",
       "      <th>award</th>\n",
       "      <th>hici</th>\n",
       "      <th>ns</th>\n",
       "      <th>pub</th>\n",
       "      <th>pcp</th>\n",
       "      <th>year</th>\n",
       "      <th>Top50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>72.4</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>99.8</td>\n",
       "      <td>93.4</td>\n",
       "      <td>53.3</td>\n",
       "      <td>56.6</td>\n",
       "      <td>70.9</td>\n",
       "      <td>66.9</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>41.1</td>\n",
       "      <td>72.2</td>\n",
       "      <td>88.5</td>\n",
       "      <td>70.9</td>\n",
       "      <td>72.3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>University of California, Berkeley</td>\n",
       "      <td>71.8</td>\n",
       "      <td>76.0</td>\n",
       "      <td>69.4</td>\n",
       "      <td>73.9</td>\n",
       "      <td>72.2</td>\n",
       "      <td>52.7</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Massachusetts Institute of Technology (MIT)</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.6</td>\n",
       "      <td>66.7</td>\n",
       "      <td>65.8</td>\n",
       "      <td>64.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   world_rank                              university_name  alumni  award  \\\n",
       "0         1.0                           Harvard University   100.0  100.0   \n",
       "1         2.0                      University of Cambridge    99.8   93.4   \n",
       "2         3.0                          Stanford University    41.1   72.2   \n",
       "3         4.0           University of California, Berkeley    71.8   76.0   \n",
       "4         5.0  Massachusetts Institute of Technology (MIT)    74.0   80.6   \n",
       "\n",
       "    hici     ns    pub   pcp  year  Top50  \n",
       "0  100.0  100.0  100.0  72.4  2005   True  \n",
       "1   53.3   56.6   70.9  66.9  2005   True  \n",
       "2   88.5   70.9   72.3  65.0  2005   True  \n",
       "3   69.4   73.9   72.2  52.7  2005   True  \n",
       "4   66.7   65.8   64.3  53.0  2005   True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, False,  True, False])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[100. , 100. , 100. ],\n",
       "       [ 99.8,  53.3,  70.9],\n",
       "       [ 41.1,  88.5,  72.3],\n",
       "       ...,\n",
       "       [ 13.6,   3.6,  25.1],\n",
       "       [  0. ,   0. ,  28.8],\n",
       "       [  0. ,  14.9,  25. ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected features are: ['pub', 'hici', 'alumni']\n",
      "------ Shanghai100 ------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True, False, False])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[100. , 100. , 100. ],\n",
       "       [ 93.4,  53.3,  56.6],\n",
       "       [ 72.2,  88.5,  70.9],\n",
       "       ...,\n",
       "       [  0. ,   3.6,  10.8],\n",
       "       [  0. ,   0. ,  12.2],\n",
       "       [  0. ,  14.9,   7.5]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected features are: ['ns', 'hici', 'award']\n",
      "------ Times10 ------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world_rank</th>\n",
       "      <th>university_name</th>\n",
       "      <th>country</th>\n",
       "      <th>teaching</th>\n",
       "      <th>international</th>\n",
       "      <th>research</th>\n",
       "      <th>citations</th>\n",
       "      <th>income</th>\n",
       "      <th>num_students</th>\n",
       "      <th>student_staff_ratio</th>\n",
       "      <th>international_students</th>\n",
       "      <th>female_male_ratio</th>\n",
       "      <th>year</th>\n",
       "      <th>females</th>\n",
       "      <th>Top50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>California Institute of Technology</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>97.7</td>\n",
       "      <td>54.6</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>83.7</td>\n",
       "      <td>2243.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.27</td>\n",
       "      <td>33 : 67</td>\n",
       "      <td>2011</td>\n",
       "      <td>33.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>97.8</td>\n",
       "      <td>82.3</td>\n",
       "      <td>91.4</td>\n",
       "      <td>99.9</td>\n",
       "      <td>87.5</td>\n",
       "      <td>11074.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>37 : 63</td>\n",
       "      <td>2011</td>\n",
       "      <td>37.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>98.3</td>\n",
       "      <td>29.5</td>\n",
       "      <td>98.1</td>\n",
       "      <td>99.2</td>\n",
       "      <td>64.3</td>\n",
       "      <td>15596.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.22</td>\n",
       "      <td>42 : 58</td>\n",
       "      <td>2011</td>\n",
       "      <td>42.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>90.5</td>\n",
       "      <td>77.7</td>\n",
       "      <td>94.1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>18812.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>46 : 54</td>\n",
       "      <td>2011</td>\n",
       "      <td>46.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>University of Oxford</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>88.2</td>\n",
       "      <td>77.2</td>\n",
       "      <td>93.9</td>\n",
       "      <td>95.1</td>\n",
       "      <td>73.5</td>\n",
       "      <td>19919.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.34</td>\n",
       "      <td>46 : 54</td>\n",
       "      <td>2011</td>\n",
       "      <td>46.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   world_rank                        university_name  \\\n",
       "1         2.0     California Institute of Technology   \n",
       "2         3.0  Massachusetts Institute of Technology   \n",
       "3         4.0                    Stanford University   \n",
       "5         6.0                University of Cambridge   \n",
       "6         6.0                   University of Oxford   \n",
       "\n",
       "                    country  teaching  international  research  citations  \\\n",
       "1  United States of America      97.7           54.6      98.0       99.9   \n",
       "2  United States of America      97.8           82.3      91.4       99.9   \n",
       "3  United States of America      98.3           29.5      98.1       99.2   \n",
       "5            United Kingdom      90.5           77.7      94.1       94.0   \n",
       "6            United Kingdom      88.2           77.2      93.9       95.1   \n",
       "\n",
       "   income  num_students  student_staff_ratio  international_students  \\\n",
       "1    83.7        2243.0                  6.9                    0.27   \n",
       "2    87.5       11074.0                  9.0                    0.33   \n",
       "3    64.3       15596.0                  7.8                    0.22   \n",
       "5    57.0       18812.0                 11.8                    0.34   \n",
       "6    73.5       19919.0                 11.6                    0.34   \n",
       "\n",
       "  female_male_ratio  year  females  Top50  \n",
       "1           33 : 67  2011     33.0   True  \n",
       "2           37 : 63  2011     37.0   True  \n",
       "3           42 : 58  2011     42.0   True  \n",
       "5           46 : 54  2011     46.0   True  \n",
       "6           46 : 54  2011     46.0   True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True, False, False, False,  True,  True])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[9.99e+01, 2.70e-01, 3.30e+01],\n",
       "       [9.99e+01, 3.30e-01, 3.70e+01],\n",
       "       [9.92e+01, 2.20e-01, 4.20e+01],\n",
       "       ...,\n",
       "       [1.93e+01, 2.00e-02, 3.60e+01],\n",
       "       [1.35e+01, 8.00e-02, 2.80e+01],\n",
       "       [2.86e+01, 4.00e-02, 4.30e+01]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected features are: ['international_students', 'females', 'citations']\n",
      "------ Times100 ------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False,  True,  True, False, False, False,  True, False])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[9.80e+01, 9.99e+01, 2.70e-01],\n",
       "       [9.14e+01, 9.99e+01, 3.30e-01],\n",
       "       [9.81e+01, 9.92e+01, 2.20e-01],\n",
       "       ...,\n",
       "       [7.60e+00, 1.93e+01, 2.00e-02],\n",
       "       [1.60e+01, 1.35e+01, 8.00e-02],\n",
       "       [1.83e+01, 2.86e+01, 4.00e-02]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected features are: ['research', 'international_students', 'citations']\n"
     ]
    }
   ],
   "source": [
    "# C) Does it change if we choose the top 10 or top 100?\n",
    "\n",
    "# I just copy-paste the previous code and change to <11 and <101\n",
    "\n",
    "print('------ Shanghai10 ------')\n",
    "sg_data.head()\n",
    "X = sg_data.iloc[:,2:8].values\n",
    "sg_data['Top10'] = sg_data['world_rank']<11   # HERE THE DIFFERENCE\n",
    "Y = sg_data['Top10'].values\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(X, Y)\n",
    "fit.support_\n",
    "features = fit.transform(X)\n",
    "features\n",
    "results = sorted(zip(fit.support_, sg_data.iloc[:,2:8].columns),reverse=True)[:3]\n",
    "print('The selected features are: '+ str([x[1] for x in results]))\n",
    "print('------ Shanghai100 ------')\n",
    "sg_data['Top100'] = sg_data['world_rank']<101   # HERE THE DIFFERENCE\n",
    "Y = sg_data['Top100'].values\n",
    "fit = rfe.fit(X, Y)\n",
    "fit.support_\n",
    "features = fit.transform(X)\n",
    "features\n",
    "results = sorted(zip(fit.support_, sg_data.iloc[:,2:8].columns),reverse=True)[:3]\n",
    "print('The selected features are: '+ str([x[1] for x in results]))\n",
    "\n",
    "\n",
    "print('------ Times10 ------')\n",
    "times.head()\n",
    "X = pd.concat([times.iloc[:,3:11],times['females']],axis=1).values\n",
    "times['Top10'] = times['world_rank']<11            # HERE THE DIFFERENCE\n",
    "Y = times['Top10'].values\n",
    "fit = rfe.fit(X, Y)\n",
    "fit.support_\n",
    "features = fit.transform(X)\n",
    "features\n",
    "results = sorted(zip(fit.support_, pd.concat([times.iloc[:,3:11],times['females']],axis=1).columns),reverse=True)[:3]\n",
    "print('The selected features are: '+ str([x[1] for x in results]))\n",
    "print('------ Times100 ------')\n",
    "times['Top100'] = times['world_rank']<101         # HERE THE DIFFERENCE\n",
    "Y = times['Top100'].values\n",
    "fit = rfe.fit(X, Y)\n",
    "fit.support_\n",
    "features = fit.transform(X)\n",
    "features\n",
    "results = sorted(zip(fit.support_, pd.concat([times.iloc[:,3:11],times['females']],axis=1).columns),reverse=True)[:3]\n",
    "print('The selected features are: '+ str([x[1] for x in results]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Principal Component Analysis</h1>\n",
    "\n",
    "Principal Component Analysis is a data reduction technique using linear algebra. The idea here is to \"compress\" several dimensions into pricipal components. \n",
    "\n",
    "One problem of PCA is the explainability. Once you compressed the attributes into principal components you can no longer to refer them individually establishing causality links or relationships. \n",
    "\n",
    "A property of PCA is that you can choose the number of dimensions or principal components. In our example we will select 3 principal components. \n",
    "\n",
    "For Principal Component Analysis you use the <b>PCA</b> class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance: [1.000e+00 3.215e-06 1.598e-06]\n",
      "\n",
      "Principal Components have little resemblance to the source data attributes\n",
      "\n",
      "[[ 0.000 -0.000  0.000 -0.000 -0.000  1.000  0.000 -0.000  0.000]\n",
      " [ 0.442  0.315  0.570  0.542  0.287  0.000 -0.065  0.002 -0.011]\n",
      " [ 0.178 -0.588  0.187 -0.343  0.626 -0.000 -0.052 -0.002 -0.276]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "p_indians.head()\n",
    "\n",
    "#PCA\n",
    "pca = PCA(n_components=3) # número de componentes que quiero. Menor o igual a los que tienes.\n",
    "pca_fit = pca.fit(X)\n",
    "\n",
    "print(f\"Explained variance: {pca_fit.explained_variance_ratio_}\")\n",
    "print()\n",
    "\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "print(\"Principal Components have little resemblance to the source data attributes\")\n",
    "print()\n",
    "print(pca_fit.components_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in each vector try to explain as much variance as possible.\n",
    "#insulina con otras cosas, pero insulina domina en el primer vector. Explica 88% of variance. la gran parte de la explicación.\n",
    "#el segundo vector es glucosa. Correlacionado negativamente.solo explica 6%\n",
    "#el tercero is whatever.\n",
    "#probablemente lo puedas reducir a dos vectores o incluso a uno.\n",
    "#pero cuando lo quieres explicar.. difícil porque not relate to real thing.\n",
    "#if you care about fit then perfect.\n",
    "#este es el mejor caso porque tienes a uno que domina el vector, pero si tuvieras a varios dominando... entonces difícil.\n",
    "#reduce complexity with less attributes through calculating the variances of the dimensions.\n",
    "#these are the eigenvalues of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Feature Importance </h1>\n",
    "\n",
    "One of the added features of tree based algorithms is that they can be used to estimate the importance of each feature and use it to refine the model to different levels depending on where we want to situate ourselves in the tension between explainability and accuracy. \n",
    "\n",
    "In this example we are going to use the ExtraTreesClassifier, but the technique is commonly used in all tree algoritms. \n",
    "\n",
    "For this example of assessing feature importance with trees we will use the <b>ExtraTreesClassifier</b> class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.272  0.044  0.275  0.236  0.050  0.030  0.028  0.036  0.030]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "p_indians.head()\n",
    "\n",
    "model = ExtraTreesClassifier(n_estimators=100) # the number of trees in the forest (tree en este caso como variable, ensemble)\n",
    "model.fit(X,Y) # Adaptar ensemble a tu modelo.\n",
    "\n",
    "print(model.feature_importances_) # Sacar los números de importancia... cuanto mayor más importante. \n",
    "# la importancia podría ser como un peso, un coeficiente.\n",
    "\n",
    "#esto es un random forest.\n",
    "#hay 3 cosas importantes: cuántos trees in the forest, the learning? rate and finally how deep are the trees.\n",
    "#3 parameters. But each library has a name for the same.\n",
    "#presentarías el vector como un histograma para que se pueda ver qué es lo más importante y como rankeado por importancia.\n",
    "#you run it a few times, if the result is the same then is pretty robust. If not, then maybe add more trees, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"red\" size=6>Mission 2</font>\n",
    "\n",
    "a) Using the Shangai Data find the top attributes with a tree classifier for top-10, top-50 and top-100.  \n",
    "<br>\n",
    "b) Same for the Times ranking. \n",
    "<br><br>\n",
    "\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) Using the Shangai Data find the top attributes with a tree classifier for top-10, top-50 and top-100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world_rank</th>\n",
       "      <th>university_name</th>\n",
       "      <th>alumni</th>\n",
       "      <th>award</th>\n",
       "      <th>hici</th>\n",
       "      <th>ns</th>\n",
       "      <th>pub</th>\n",
       "      <th>pcp</th>\n",
       "      <th>year</th>\n",
       "      <th>Top50</th>\n",
       "      <th>Top10</th>\n",
       "      <th>Top100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>72.4</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>99.8</td>\n",
       "      <td>93.4</td>\n",
       "      <td>53.3</td>\n",
       "      <td>56.6</td>\n",
       "      <td>70.9</td>\n",
       "      <td>66.9</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>41.1</td>\n",
       "      <td>72.2</td>\n",
       "      <td>88.5</td>\n",
       "      <td>70.9</td>\n",
       "      <td>72.3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>University of California, Berkeley</td>\n",
       "      <td>71.8</td>\n",
       "      <td>76.0</td>\n",
       "      <td>69.4</td>\n",
       "      <td>73.9</td>\n",
       "      <td>72.2</td>\n",
       "      <td>52.7</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Massachusetts Institute of Technology (MIT)</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.6</td>\n",
       "      <td>66.7</td>\n",
       "      <td>65.8</td>\n",
       "      <td>64.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   world_rank                              university_name  alumni  award  \\\n",
       "0         1.0                           Harvard University   100.0  100.0   \n",
       "1         2.0                      University of Cambridge    99.8   93.4   \n",
       "2         3.0                          Stanford University    41.1   72.2   \n",
       "3         4.0           University of California, Berkeley    71.8   76.0   \n",
       "4         5.0  Massachusetts Institute of Technology (MIT)    74.0   80.6   \n",
       "\n",
       "    hici     ns    pub   pcp  year  Top50  Top10  Top100  \n",
       "0  100.0  100.0  100.0  72.4  2005   True   True    True  \n",
       "1   53.3   56.6   70.9  66.9  2005   True   True    True  \n",
       "2   88.5   70.9   72.3  65.0  2005   True   True    True  \n",
       "3   69.4   73.9   72.2  52.7  2005   True   True    True  \n",
       "4   66.7   65.8   64.3  53.0  2005   True   True    True  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Shanghai10 ------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.198  0.398  0.119  0.118  0.041  0.127]\n",
      "The selected features are: ['award', 'alumni', 'pcp']\n",
      "------ Shanghai50 ------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.089  0.217  0.237  0.244  0.138  0.075]\n",
      "The selected features are: ['ns', 'hici', 'award']\n",
      "------ Shanghai100 ------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.126  0.226  0.219  0.167  0.166  0.096]\n",
      "The selected features are: ['award', 'hici', 'ns']\n"
     ]
    }
   ],
   "source": [
    "sg_data.head()\n",
    "\n",
    "print('------ Shanghai10 ------')\n",
    "\n",
    "# Specific import\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Select variables and transform to numpy arrays\n",
    "X = sg_data.iloc[:,2:8].values\n",
    "Y = sg_data['Top10'].values\n",
    "\n",
    "# Feature importance\n",
    "model = ExtraTreesClassifier(n_estimators=100)\n",
    "model.fit(X,Y)\n",
    "\n",
    "# Show results\n",
    "print(model.feature_importances_)\n",
    "results = sorted(zip(model.feature_importances_, sg_data.iloc[:,2:8].columns),reverse=True)[:3]\n",
    "print('The selected features are: '+ str([x[1] for x in results]))\n",
    "\n",
    "\n",
    "print('------ Shanghai50 ------')\n",
    "\n",
    "# Copy-paste and just change the target variable top 'Top50'\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "Y = sg_data['Top50'].values\n",
    "model = ExtraTreesClassifier(n_estimators=100)\n",
    "model.fit(X,Y)\n",
    "print(model.feature_importances_)\n",
    "results = sorted(zip(model.feature_importances_, sg_data.iloc[:,2:8].columns),reverse=True)[:3]\n",
    "print('The selected features are: '+ str([x[1] for x in results]))\n",
    "\n",
    "print('------ Shanghai100 ------')\n",
    "\n",
    "# Copy-paste and just change the target variable top 'Top100'\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "Y = sg_data['Top100'].values\n",
    "model = ExtraTreesClassifier(n_estimators=100)\n",
    "model.fit(X,Y)\n",
    "print(model.feature_importances_)\n",
    "results = sorted(zip(model.feature_importances_, sg_data.iloc[:,2:8].columns),reverse=True)[:3]\n",
    "print('The selected features are: '+ str([x[1] for x in results]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world_rank</th>\n",
       "      <th>university_name</th>\n",
       "      <th>country</th>\n",
       "      <th>teaching</th>\n",
       "      <th>international</th>\n",
       "      <th>research</th>\n",
       "      <th>citations</th>\n",
       "      <th>income</th>\n",
       "      <th>num_students</th>\n",
       "      <th>student_staff_ratio</th>\n",
       "      <th>international_students</th>\n",
       "      <th>female_male_ratio</th>\n",
       "      <th>year</th>\n",
       "      <th>females</th>\n",
       "      <th>Top50</th>\n",
       "      <th>Top10</th>\n",
       "      <th>Top100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>California Institute of Technology</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>97.7</td>\n",
       "      <td>54.6</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>83.7</td>\n",
       "      <td>2243.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.27</td>\n",
       "      <td>33 : 67</td>\n",
       "      <td>2011</td>\n",
       "      <td>33.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>97.8</td>\n",
       "      <td>82.3</td>\n",
       "      <td>91.4</td>\n",
       "      <td>99.9</td>\n",
       "      <td>87.5</td>\n",
       "      <td>11074.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>37 : 63</td>\n",
       "      <td>2011</td>\n",
       "      <td>37.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>98.3</td>\n",
       "      <td>29.5</td>\n",
       "      <td>98.1</td>\n",
       "      <td>99.2</td>\n",
       "      <td>64.3</td>\n",
       "      <td>15596.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.22</td>\n",
       "      <td>42 : 58</td>\n",
       "      <td>2011</td>\n",
       "      <td>42.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>90.5</td>\n",
       "      <td>77.7</td>\n",
       "      <td>94.1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>18812.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>46 : 54</td>\n",
       "      <td>2011</td>\n",
       "      <td>46.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>University of Oxford</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>88.2</td>\n",
       "      <td>77.2</td>\n",
       "      <td>93.9</td>\n",
       "      <td>95.1</td>\n",
       "      <td>73.5</td>\n",
       "      <td>19919.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.34</td>\n",
       "      <td>46 : 54</td>\n",
       "      <td>2011</td>\n",
       "      <td>46.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   world_rank                        university_name  \\\n",
       "1         2.0     California Institute of Technology   \n",
       "2         3.0  Massachusetts Institute of Technology   \n",
       "3         4.0                    Stanford University   \n",
       "5         6.0                University of Cambridge   \n",
       "6         6.0                   University of Oxford   \n",
       "\n",
       "                    country  teaching  international  research  citations  \\\n",
       "1  United States of America      97.7           54.6      98.0       99.9   \n",
       "2  United States of America      97.8           82.3      91.4       99.9   \n",
       "3  United States of America      98.3           29.5      98.1       99.2   \n",
       "5            United Kingdom      90.5           77.7      94.1       94.0   \n",
       "6            United Kingdom      88.2           77.2      93.9       95.1   \n",
       "\n",
       "   income  num_students  student_staff_ratio  international_students  \\\n",
       "1    83.7        2243.0                  6.9                    0.27   \n",
       "2    87.5       11074.0                  9.0                    0.33   \n",
       "3    64.3       15596.0                  7.8                    0.22   \n",
       "5    57.0       18812.0                 11.8                    0.34   \n",
       "6    73.5       19919.0                 11.6                    0.34   \n",
       "\n",
       "  female_male_ratio  year  females  Top50  Top10  Top100  \n",
       "1           33 : 67  2011     33.0   True   True    True  \n",
       "2           37 : 63  2011     37.0   True   True    True  \n",
       "3           42 : 58  2011     42.0   True   True    True  \n",
       "5           46 : 54  2011     46.0   True   True    True  \n",
       "6           46 : 54  2011     46.0   True   True    True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Times10 ------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.183  0.104  0.191  0.144  0.099  0.067  0.073  0.066  0.072]\n",
      "The selected features are: ['research', 'teaching', 'citations']\n",
      "------ Times50 ------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.269  0.058  0.287  0.168  0.053  0.036  0.040  0.051  0.038]\n",
      "The selected features are: ['research', 'teaching', 'citations']\n",
      "------ Times100 ------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.260  0.046  0.280  0.231  0.052  0.030  0.029  0.042  0.030]\n",
      "The selected features are: ['research', 'teaching', 'citations']\n"
     ]
    }
   ],
   "source": [
    "# B) Same for the Times ranking. \n",
    "\n",
    "times.head()\n",
    "\n",
    "print('------ Times10 ------')\n",
    "\n",
    "# Specific import\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Select variables and transform to numpy arrays\n",
    "X = pd.concat([times.iloc[:,3:11],times['females']],axis=1).values\n",
    "Y = times['Top10'].values\n",
    "\n",
    "# Feature importance\n",
    "model = ExtraTreesClassifier(n_estimators=100)\n",
    "model.fit(X,Y)\n",
    "\n",
    "# Show results\n",
    "print(model.feature_importances_)\n",
    "results = sorted(zip(model.feature_importances_, pd.concat([times.iloc[:,3:11],times['females']],axis=1).columns),reverse=True)[:3]\n",
    "print('The selected features are: '+ str([x[1] for x in results]))\n",
    "\n",
    "\n",
    "print('------ Times50 ------')\n",
    "\n",
    "# Copy-paste and just change the target variable top 'Top50'\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "Y = times['Top50'].values\n",
    "model = ExtraTreesClassifier(n_estimators=100)\n",
    "model.fit(X,Y)\n",
    "print(model.feature_importances_)\n",
    "results = sorted(zip(model.feature_importances_, pd.concat([times.iloc[:,3:11],times['females']],axis=1).columns),reverse=True)[:3]\n",
    "print('The selected features are: '+ str([x[1] for x in results]))\n",
    "\n",
    "print('------ Times100 ------')\n",
    "\n",
    "# Copy-paste and just change the target variable top 'Top100'\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "Y = times['Top100'].values\n",
    "model = ExtraTreesClassifier(n_estimators=100)\n",
    "model.fit(X,Y)\n",
    "print(model.feature_importances_)\n",
    "results = sorted(zip(model.feature_importances_, pd.concat([times.iloc[:,3:11],times['females']],axis=1).columns),reverse=True)[:3]\n",
    "print('The selected features are: '+ str([x[1] for x in results]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
