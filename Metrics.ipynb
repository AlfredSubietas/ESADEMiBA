{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "#sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=metrics_1.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=metrics_2.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imágenes son esenciales, know by heart dice profesor (he hecho foto por si acaso)\n",
    "false positives ej. cáncer.\n",
    "recall de los que has categorizado como positivo, dividido entre todos los positivos que existen.\n",
    "precision: seleccionamoscuáles son correctos de todos los que hemos seleccionado. \n",
    "\n",
    "precision and recall are the basic ones.\n",
    "si es la primera vez que pruebas, priorizas recall... you don't want to miss the people who have cancer. e.j.98% recall even if precision is really bad.\n",
    "haces segundo test de los seleccionados? entonces quieres precision. \n",
    "para netflix le da igual wrong recommendaiton, por lo que le importa recall, catch as many as you can - all the styles and tastes of the people.\n",
    "precision para pieza de coche, porque sino tendrás devoluciones por instalar piezas que no estaban bien.\n",
    "\n",
    "por lo que muchas veces no quieres equally precision and recall.\n",
    "\n",
    "\n",
    "then normally also talk about accuracy (is the middle measure, we normally work with it). (como hasta ahora). good medium measure. but depending on what you are doing, it is not as important.\n",
    "de los que acertamos entre todo. \n",
    "\n",
    "changing the threshold will change the balance of precision and recall.\n",
    "\n",
    "recall is also called sensitivity. is the same . but you see this terminology in doctors. biomedical sectors. suelen ir primero por recall y luego specificity, y quizá por en medio algo de precision.\n",
    "\n",
    "specificity es el opuesto de recall (1- recall). si has dicho que esa persona no tiene cáncer, asegurarte que no tiene. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Performance Metrics </h1>\n",
    "\n",
    "The choice of metrics for evaluating a model is of the utmost importance. We will tune the model, select hyperparameters and choose a particular algorithm among others, according to this metrics. \n",
    "\n",
    "In this notebook we will focus on two of the main machine learning problems and we will discuss the metrics associated with them:\n",
    "<blockquote>\n",
    "        <ul style=\"list-style-type:none;\">\n",
    "            <li> <b>1) Classification problems.</b> We will continue to use the Pima Indias onset diabetes dataset that we have been using so far. In this dataset all attributes are numeric and its a binary classification problem.</li> \n",
    "            <br>\n",
    "            <li> <b>2) Regression problems.</b> For regression we will use also a very traditional dataset, the Boston House Price. Again all input variables are numeric.</li>\n",
    "        </ul>\n",
    "</blockquote>\n",
    "\n",
    "Obviously not all problems in machine learning can be categorized as regression or classification problems, we also have clustering, association rules, topic modeling, etc... However, classification and regression remain as the most substantial ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION METRICS\n",
    "\n",
    "Classification is probably the most common problem in machine learning and many problems can be reduced to a classification problem. \n",
    "\n",
    "Here, we will review the following metrics:\n",
    "\n",
    "            1) Accuracy. \n",
    "            2) Logarithmic loss.\n",
    "            3) Area under ROC curve.\n",
    "            4) Confusion matrix.\n",
    "            5) Classification Report. \n",
    "        \n",
    "using our already familiar Pima Indians diabetes dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Pima_indians_cowboy_1889.jpg\">\n",
    "\n",
    "In this exercise we will use one of the traditional Machine Learning dataset, the Pima Indians diabetes dataset.\n",
    "\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "Content\n",
    "The datasets consists of several medical predictor variables and one target variable, <b>Outcome</b>. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n",
    "<blockquote>\n",
    "        <ul style=\"list-style-type:square;\">\n",
    "            <li>Pregnancies</li> \n",
    "            <li>Glucose</li>\n",
    "            <li>BloodPressure</li>\n",
    "            <li>SkinThickness</li>\n",
    "            <li>Insulin</li>\n",
    "            <li>BMI</li>\n",
    "            <li>DiabetesPedigreeFunction (scores de likelihood of diabetes based on family history)</li>\n",
    "            <li>Age</li>\n",
    "            <li>Outcome</li>\n",
    "        </ul>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La imagen útil de precision, etc la encontramos en wikipedia. útil tenerla a mano.\n",
    "ROC es muy popular, se ve en todas partes. be very careful. AUC. lo utilizan como accuracy?\n",
    "No puedes comparar two classifiers the number is not representative. Only compare if it's same classifier.\n",
    "ROC is way over used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1     2     3      4     5      6     7\n",
       "0  6.0  148.0  72.0  35.0    0.0  33.6  0.627  50.0\n",
       "1  1.0   85.0  66.0  29.0    0.0  26.6  0.351  31.0\n",
       "2  8.0  183.0  64.0   0.0    0.0  23.3  0.672  32.0\n",
       "3  1.0   89.0  66.0  23.0   94.0  28.1  0.167  21.0\n",
       "4  0.0  137.0  40.0  35.0  168.0  43.1  2.288  33.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Pima indians dataset and separate input and output components \n",
    "\n",
    "from numpy import set_printoptions\n",
    "set_printoptions(precision=3)\n",
    "\n",
    "filename=\"pima-indians-diabetes.data.csv\"\n",
    "names=[\"pregnancies\", \"glucose\", \"pressure\", \"skin\", \"insulin\", \"bmi\", \"pedi\", \"age\", \"outcome\"]\n",
    "p_indians=pd.read_csv(filename, names=names)\n",
    "p_indians.head()\n",
    "\n",
    "# First we separate into input and output components\n",
    "array=p_indians.values\n",
    "X=array[:,0:8]\n",
    "Y=array[:,8]\n",
    "np.set_printoptions(suppress=True)\n",
    "X\n",
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Classification Accuracy </h1>\n",
    "\n",
    "Accuracy is the ratio of correct predictions over all predictions. It is by far the most used metrics. \n",
    "\n",
    "However, it is only suitable when classes are balanced and errors in each class are equally important. For example whe it is equally important to missclassify a healthy person as having cancer (Type I) or a sick one as healty (Type II). As you can guess, in many cases this is not the case and accuracy is many times misused. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression, k-fold 10 - Accuracy 76.951% (4.841%)\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "p_indians.head()\n",
    "\n",
    "# KFold\n",
    "splits=10\n",
    "kfold=KFold(n_splits=splits, random_state=7)\n",
    "scoring=\"accuracy\"\n",
    "\n",
    "\n",
    "#Logistic regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Obtain the performance measure - accuracy\n",
    "results = cross_val_score(model, X, Y, scoring=scoring, cv=kfold)\n",
    "\n",
    "print(f'Logistic regression, k-fold {splits:d} - Accuracy {results.mean()*100:.3f}% ({results.std()*100:.3f}%)')\n",
    "\n",
    "# A: en vex de accuracy puedo poner precision como otra medida a mirar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Logarithmic Loss</h1>\n",
    "\n",
    "Logarithmic loss (or logloss) is a performance metric for evaluating predictions of probabilities of membership to a clas as a scalar between 0 and 1 that is seen as a measure of confidence. \n",
    "\n",
    "Correct and incorrect predictions are rewarded or punished according to the confidence on the prediction. \n",
    "Each predicted probability is compared to the actual class output value (0 or 1) and a score is calculated that penalizes the probability based on the distance from the expected value.The penalty is logarithmic, offering a small penalty for small differences (0.1 or 0.2) and a large one for a large difference (0.9 or 1.0).\n",
    "\n",
    "cross_val_score inverts (expressing the inversion with a - sign) the measure, therefore 0 is better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression, k-fold 10 - Logloss -0.493 (0.047)\n"
     ]
    }
   ],
   "source": [
    "# Logarithmic Loss\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "p_indians.head()\n",
    "\n",
    "# KFold\n",
    "splits=10\n",
    "kfold=KFold(n_splits=splits, random_state=7)\n",
    "scoring=\"neg_log_loss\"\n",
    "\n",
    "#Logistic regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Obtain the performance measure - accuracy\n",
    "results = cross_val_score(model, X, Y, scoring=scoring, cv=kfold)\n",
    "\n",
    "print(f'Logistic regression, k-fold {splits:d} - Logloss {results.mean():5.3f} ({results.std():5.3f})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"AUC.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Area under ROC curve</h1>\n",
    "\n",
    "Area under the ROC curve (AUC for short) is a metric used in binary classifications. \n",
    "\n",
    "It represents the ability of the model to discriminate between positive and negative classes. An AUC of 0.5 represents a model that is as good as random, while an area of 1 represents a perfect model. \n",
    "\n",
    "The area under the curve can be broken down into two metrics: sentitivity (recall) and specificity. In general any binary classification problem is a tradeoff between these two measures. \n",
    "\n",
    "        - Sensitivity (True positive rate or recall). Represents the number of instances of the positive class that were correctly classified. \n",
    "        - Specificity (True negative rate). Number of instances of the negative class classified correctly. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression, k-fold 10 - AUC 0.824 (0.041)\n"
     ]
    }
   ],
   "source": [
    "# Area under ROC curve\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "p_indians.head()\n",
    "\n",
    "# KFold\n",
    "splits=10\n",
    "kfold=KFold(n_splits=splits, random_state=7)\n",
    "scoring=\"roc_auc\"\n",
    "\n",
    "#Logistic regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Obtain the performance measure - accuracy\n",
    "results = cross_val_score(model, X, Y, scoring=scoring, cv=kfold)\n",
    "\n",
    "print(f'Logistic regression, k-fold {splits:d} - AUC {results.mean():5.3f} ({results.std():5.3f})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"confusionMatrix.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Confusion Matrix </h1>\n",
    "\n",
    "The confusion matrix is a presentation of the accuracy of the model in its four classes: True Positives, False Positives, False Negatives and True Negatives. \n",
    "\n",
    "From it we can easily derive Precision, Recall, Specificity and Accuracy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[130  17]\n",
      " [ 38  46]]\n",
      "\n",
      "Accuracy 76.19048\n",
      "Accuracy check with conf. matrix 76.19048\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "p_indians.head()\n",
    "\n",
    "test_size=0.3\n",
    "seed=7\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_predicted = model.predict(X_test)\n",
    "\n",
    "c_matrix=confusion_matrix(Y_test, Y_predicted)\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(c_matrix)\n",
    "\n",
    "print()\n",
    "print(f'Accuracy {model.score(X_test, Y_test)*100:.5f}') # esto automáticamente ya te hace accuracy\n",
    "print(f'Accuracy check with conf. matrix {(c_matrix[0,0]+c_matrix[1,1])/c_matrix.sum()*100:.5f}') # aquí lo haces a mano.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Classification Report</h1>\n",
    "\n",
    "The scikit-learn library provides a report that is convenient and useful in terms of summarizing many of the measures that are commonly used together with accuracy. \n",
    "\n",
    "For each class it presents:\n",
    "<blockquote>\n",
    "1) Precision. $Precision = \\frac{True Positives}{True Positives + False Posities}$\n",
    "\n",
    "2) Recall (also known as Sensitivity). $Recall = \\frac{True Positives}{True Positivies + False Negatives}$\n",
    "\n",
    "3) F1 score. It's the harmonic mean of precision and recall. $F1 = 2 ·\\frac{precision · recall}{precision + recall}$    , provides a good balance between precision and recall when classes are unevenly distributed. Best is 1, worst is 0.   \n",
    "\n",
    "4) Support. It's the number of elements of each class in Y_test.\n",
    "\n",
    "</blockquote>\n",
    "The reported averages include:\n",
    "\n",
    "        1) Macro average. Averaging the unweighted mean per label. \n",
    "        2) Weighted average. Averaging the support-weighted mean per label. \n",
    "        3) Sample average. Only for multilabel classification. \n",
    "        4) Micro average. Accuracy for a binary classification. Averaging the total true positives, false negatives and false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 76.19048\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.77381   0.88435   0.82540       147\n",
      "         1.0    0.73016   0.54762   0.62585        84\n",
      "\n",
      "    accuracy                        0.76190       231\n",
      "   macro avg    0.75198   0.71599   0.72562       231\n",
      "weighted avg    0.75794   0.76190   0.75283       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "p_indians.head()\n",
    "\n",
    "test_size=0.3\n",
    "seed=7\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_predicted = model.predict(X_test)\n",
    "\n",
    "report = classification_report(Y_test, Y_predicted, digits=5) # digits cuántos decimales quieres.\n",
    "\n",
    "\n",
    "print(f'Accuracy {model.score(X_test, Y_test)*100:.5f}')\n",
    "print()\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"red\" size=6>Mission 1</font>\n",
    "\n",
    "We will use our predictions for top-10 and top-50 the Shanghai and Times Dataset\n",
    "<br><br>\n",
    "a) For the Shanghai dataset evaluate accuracy, logloss, AUC, confusion matrix and classification report. Briefly discuss the diferences. \n",
    "<br><br>\n",
    "b) Same for the Times ranking. \n",
    "<br><br>\n",
    "\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world_rank</th>\n",
       "      <th>university_name</th>\n",
       "      <th>alumni</th>\n",
       "      <th>award</th>\n",
       "      <th>hici</th>\n",
       "      <th>ns</th>\n",
       "      <th>pub</th>\n",
       "      <th>pcp</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>72.4</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>99.8</td>\n",
       "      <td>93.4</td>\n",
       "      <td>53.3</td>\n",
       "      <td>56.6</td>\n",
       "      <td>70.9</td>\n",
       "      <td>66.9</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>41.1</td>\n",
       "      <td>72.2</td>\n",
       "      <td>88.5</td>\n",
       "      <td>70.9</td>\n",
       "      <td>72.3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>University of California, Berkeley</td>\n",
       "      <td>71.8</td>\n",
       "      <td>76.0</td>\n",
       "      <td>69.4</td>\n",
       "      <td>73.9</td>\n",
       "      <td>72.2</td>\n",
       "      <td>52.7</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Massachusetts Institute of Technology (MIT)</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.6</td>\n",
       "      <td>66.7</td>\n",
       "      <td>65.8</td>\n",
       "      <td>64.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   world_rank                              university_name  alumni  award  \\\n",
       "0         1.0                           Harvard University   100.0  100.0   \n",
       "1         2.0                      University of Cambridge    99.8   93.4   \n",
       "2         3.0                          Stanford University    41.1   72.2   \n",
       "3         4.0           University of California, Berkeley    71.8   76.0   \n",
       "4         5.0  Massachusetts Institute of Technology (MIT)    74.0   80.6   \n",
       "\n",
       "    hici     ns    pub   pcp  year  \n",
       "0  100.0  100.0  100.0  72.4  2005  \n",
       "1   53.3   56.6   70.9  66.9  2005  \n",
       "2   88.5   70.9   72.3  65.0  2005  \n",
       "3   69.4   73.9   72.2  52.7  2005  \n",
       "4   66.7   65.8   64.3  53.0  2005  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------- ACCURACY ------------------------------------------------------------\n",
      "------------------------------------------- ACCURACY TOP10 ------------------------------------------------------\n",
      "Logistic regression TOP10, k-fold 10 - Accuracy 99.836% (0.179%)\n",
      "------------------------------------------- ACCURACY TOP50 ------------------------------------------------------\n",
      "Logistic regression TOP50, k-fold 10 - Accuracy 98.687% (0.307%)\n",
      "\n",
      "------------------------------------------- LOGLOSS ------------------------------------------------------------\n",
      "------------------------------------------- LOGLOSS TOP10 ------------------------------------------------------\n",
      "Logistic regression, k-fold 5 - Logloss -0.009 (0.005)\n",
      "------------------------------------------- LOGLOSS TOP50 ------------------------------------------------------\n",
      "Logistic regression, k-fold 5 - Logloss -0.042 (0.009)\n",
      "\n",
      "------------------------------------------- AUC ------------------------------------------------------------\n",
      "------------------------------------------- AUC TOP10 ------------------------------------------------------\n",
      "Logistic regression, k-fold 5 - AUC 1.000 (0.001)\n",
      "------------------------------------------- AUC TOP50 ------------------------------------------------------\n",
      "Logistic regression, k-fold 5 - AUC 0.998 (0.001)\n",
      "\n",
      "------------------------------------------- CONFUSION MATRIX --------------------------------------------------------\n",
      "------------------------------------------- CONFUSION MATRIX TOP10 --------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[1435    0]\n",
      " [   4   24]]\n",
      "\n",
      "Accuracy 99.72659\n",
      "Accuracy check with conf. matrix 99.72659\n",
      "------------------------------------------- CONFUSION MATRIX TOP50 --------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[1294    9]\n",
      " [   9  151]]\n",
      "\n",
      "Accuracy 98.76965\n",
      "Accuracy check with conf. matrix 98.76965\n",
      "\n",
      "------------------------------------------- CLASSIFICATION REPORT ----------------------------------------------------\n",
      "------------------------------------------- CLASSIFICATION REPORT TOP10 ----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 99.72659\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99722   1.00000   0.99861      1435\n",
      "           1    1.00000   0.85714   0.92308        28\n",
      "\n",
      "    accuracy                        0.99727      1463\n",
      "   macro avg    0.99861   0.92857   0.96084      1463\n",
      "weighted avg    0.99727   0.99727   0.99716      1463\n",
      "\n",
      "------------------------------------------- CLASSIFICATION REPORT TOP50 ----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 98.76965\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99309   0.99309   0.99309      1303\n",
      "           1    0.94375   0.94375   0.94375       160\n",
      "\n",
      "    accuracy                        0.98770      1463\n",
      "   macro avg    0.96842   0.96842   0.96842      1463\n",
      "weighted avg    0.98770   0.98770   0.98770      1463\n",
      "\n",
      "\n",
      "Discussion of differences in the cell below\n"
     ]
    }
   ],
   "source": [
    "# A) For the Shanghai dataset evaluate accuracy, logloss, AUC, confusion matrix and classification report. \n",
    "# ... Briefly discuss the diferences. \n",
    "\n",
    "# Import dataset (code copy-pasted from my previous notebook)\n",
    "sg_data = pd.read_csv('shanghaiData.csv')\n",
    "sg_data['world_rank'] = sg_data['world_rank'].str.split('-').str.get(0).astype(float)\n",
    "sg_data.drop(columns=['national_rank','total_score'], inplace=True)\n",
    "sg_data.dropna(inplace=True)\n",
    "sg_data.head()\n",
    "\n",
    "\n",
    "print('------------------------------------------- ACCURACY ------------------------------------------------------------')\n",
    "print('------------------------------------------- ACCURACY TOP10 ------------------------------------------------------')\n",
    "# Imports (not necessary, because it is already above)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# KFold\n",
    "splits=10\n",
    "kfold=KFold(n_splits=splits, random_state=7)\n",
    "\n",
    "# Select input and target variables and transform to numpy arrays.\n",
    "X = sg_data.iloc[:,2:8].values\n",
    "sg_data['Top10'] = sg_data['world_rank']<11\n",
    "Y = sg_data['Top10'].values\n",
    "\n",
    "#Logistic regression\n",
    "scoring=\"accuracy\"\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Obtain the performance measure - accuracy\n",
    "results = cross_val_score(model, X, Y, scoring=scoring, cv=kfold)\n",
    "\n",
    "#Show results\n",
    "print(f'Logistic regression TOP10, k-fold {splits:d} - Accuracy {results.mean()*100:5.3f}% ({results.std()*100:5.3f}%)')\n",
    "print('------------------------------------------- ACCURACY TOP50 ------------------------------------------------------')\n",
    "# Select input and target variables and transform to numpy arrays.\n",
    "X = sg_data.iloc[:,2:8].values\n",
    "sg_data['Top50'] = sg_data['world_rank']<51\n",
    "Y = sg_data['Top50'].values\n",
    "\n",
    "#Logistic regression\n",
    "scoring=\"accuracy\"\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Obtain the performance measure - accuracy\n",
    "results = cross_val_score(model, X, Y, scoring=scoring, cv=kfold)\n",
    "\n",
    "#Show results\n",
    "print(f'Logistic regression TOP50, k-fold {splits:d} - Accuracy {results.mean()*100:5.3f}% ({results.std()*100:5.3f}%)')\n",
    "\n",
    "print() # esto es un enter en jupyter notebook\n",
    "print('------------------------------------------- LOGLOSS ------------------------------------------------------------')\n",
    "print('------------------------------------------- LOGLOSS TOP10 ------------------------------------------------------')\n",
    "# Imports and KFold (not necessary, because it is already above)\n",
    "# KFold\n",
    "splits=5 # I am using less than 10 folds, otherwise impacted because I am doing top10, then the first is all 1, the rest 0.\n",
    "kfold=KFold(n_splits=splits, random_state=7)\n",
    "# Select input and target variables and transform to numpy arrays.\n",
    "X = sg_data.iloc[:,2:8].values\n",
    "sg_data['Top10'] = sg_data['world_rank']<11 # this is boolean, I need it in 1 and 0 for log regression!!!!!!!!\n",
    "dicc={True:1,False:0}\n",
    "Y = sg_data['Top10'].replace(dicc)\n",
    "Y = Y.values # transform to numpy array\n",
    "\n",
    "#Logistic regression\n",
    "scoring=\"neg_log_loss\" \n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Obtain the performance measure - accuracy\n",
    "#from sklearn.metrics import log_loss\n",
    "#model.fit(X, Y)\n",
    "#a = model.predict(X)\n",
    "#log_loss(Y, a)\n",
    "results = cross_val_score(model, X, Y, scoring=scoring, cv=kfold)\n",
    "\n",
    "# Show\n",
    "print(f'Logistic regression, k-fold {splits:d} - Logloss {results.mean():5.3f} ({results.std():5.3f})')\n",
    "\n",
    "print('------------------------------------------- LOGLOSS TOP50 ------------------------------------------------------')\n",
    "# Imports and KFold (not necessary, because it is already above)\n",
    "# KFold\n",
    "splits=5 # I am using less than 10 folds, otherwise impacted because I am doing top10, then the first is all 1, the rest 0.\n",
    "kfold=KFold(n_splits=splits, random_state=7)\n",
    "# Select input and target variables and transform to numpy arrays.\n",
    "X = sg_data.iloc[:,2:8].values\n",
    "sg_data['Top10'] = sg_data['world_rank']<51 #change this\n",
    "dicc={True:1,False:0}\n",
    "Y = sg_data['Top10'].replace(dicc)\n",
    "Y = Y.values \n",
    "\n",
    "#Logistic regression\n",
    "scoring=\"neg_log_loss\" \n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Obtain the performance measure - accuracy\n",
    "results = cross_val_score(model, X, Y, scoring=scoring, cv=kfold)\n",
    "\n",
    "# Show\n",
    "print(f'Logistic regression, k-fold {splits:d} - Logloss {results.mean():5.3f} ({results.std():5.3f})')\n",
    "\n",
    "print()\n",
    "print('------------------------------------------- AUC ------------------------------------------------------------')\n",
    "print('------------------------------------------- AUC TOP10 ------------------------------------------------------')\n",
    "# Imports\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Select variables\n",
    "X = sg_data.iloc[:,2:8].values\n",
    "sg_data['Top10'] = sg_data['world_rank']<11 \n",
    "dicc={True:1,False:0}\n",
    "Y = sg_data['Top10'].replace(dicc)\n",
    "Y = Y.values\n",
    "# KFold\n",
    "splits=5\n",
    "kfold=KFold(n_splits=splits, random_state=7)\n",
    "scoring=\"roc_auc\"\n",
    "#Logistic regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "# Obtain the performance measure - accuracy\n",
    "results = cross_val_score(model, X, Y, scoring=scoring, cv=KFold(n_splits=splits, random_state=7))\n",
    "\n",
    "print(f'Logistic regression, k-fold {splits:d} - AUC {results.mean():5.3f} ({results.std():5.3f})')\n",
    "\n",
    "print('------------------------------------------- AUC TOP50 ------------------------------------------------------')\n",
    "# Imports\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Select variables\n",
    "X = sg_data.iloc[:,2:8].values\n",
    "sg_data['Top10'] = sg_data['world_rank']<51 # changed this, copy-pasted from top10\n",
    "dicc={True:1,False:0}\n",
    "Y = sg_data['Top10'].replace(dicc)\n",
    "Y = Y.values\n",
    "# KFold\n",
    "splits=5\n",
    "kfold=KFold(n_splits=splits, random_state=7)\n",
    "scoring=\"roc_auc\"\n",
    "#Logistic regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "# Obtain the performance measure - accuracy\n",
    "results = cross_val_score(model, X, Y, scoring=scoring, cv=KFold(n_splits=splits, random_state=7))\n",
    "\n",
    "print(f'Logistic regression, k-fold {splits:d} - AUC {results.mean():5.3f} ({results.std():5.3f})')\n",
    "\n",
    "print()\n",
    "print('------------------------------------------- CONFUSION MATRIX --------------------------------------------------------')\n",
    "print('------------------------------------------- CONFUSION MATRIX TOP10 --------------------------------------------------')\n",
    "# Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Select variables (not necessary since I have them defined above, but to practice)\n",
    "X = sg_data.iloc[:,2:8].values\n",
    "sg_data['Top10'] = sg_data['world_rank']<11\n",
    "dicc={True:1,False:0}\n",
    "Y = sg_data['Top10'].replace(dicc)\n",
    "Y = Y.values\n",
    "\n",
    "# Select arguments, split the data, log regression, confusion matrix\n",
    "test_size=0.3\n",
    "seed=7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, Y_train)\n",
    "Y_predicted = model.predict(X_test)\n",
    "c_matrix=confusion_matrix(Y_test, Y_predicted)\n",
    "\n",
    "# Show\n",
    "print(\"Confusion Matrix\")\n",
    "print(c_matrix)\n",
    "\n",
    "print()\n",
    "print(f'Accuracy {model.score(X_test, Y_test)*100:.5f}') # esto automáticamente ya te hace accuracy\n",
    "print(f'Accuracy check with conf. matrix {(c_matrix[0,0]+c_matrix[1,1])/c_matrix.sum()*100:.5f}') # aquí lo haces a mano.\n",
    "\n",
    "print('------------------------------------------- CONFUSION MATRIX TOP50 --------------------------------------------------')\n",
    "# Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Select variables (not necessary since I have them defined above, but to practice)\n",
    "X = sg_data.iloc[:,2:8].values\n",
    "sg_data['Top10'] = sg_data['world_rank']<51 # changed this, copy-pasted from top10\n",
    "dicc={True:1,False:0}\n",
    "Y = sg_data['Top10'].replace(dicc)\n",
    "Y = Y.values\n",
    "\n",
    "# Select arguments, split the data, log regression, confusion matrix\n",
    "test_size=0.3\n",
    "seed=7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, Y_train)\n",
    "Y_predicted = model.predict(X_test)\n",
    "c_matrix=confusion_matrix(Y_test, Y_predicted)\n",
    "\n",
    "# Show\n",
    "print(\"Confusion Matrix\")\n",
    "print(c_matrix)\n",
    "\n",
    "print()\n",
    "print(f'Accuracy {model.score(X_test, Y_test)*100:.5f}') # esto automáticamente ya te hace accuracy\n",
    "print(f'Accuracy check with conf. matrix {(c_matrix[0,0]+c_matrix[1,1])/c_matrix.sum()*100:.5f}') # aquí lo haces a mano.\n",
    "\n",
    "\n",
    "print()\n",
    "print('------------------------------------------- CLASSIFICATION REPORT ----------------------------------------------------')\n",
    "print('------------------------------------------- CLASSIFICATION REPORT TOP10 ----------------------------------------------')\n",
    "# Classification Report \n",
    "\n",
    "# Imports (although already above, just for practice)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Select variables\n",
    "X = sg_data.iloc[:,2:8].values\n",
    "sg_data['Top10'] = sg_data['world_rank']<11\n",
    "dicc={True:1,False:0}\n",
    "Y = sg_data['Top10'].replace(dicc)\n",
    "Y = Y.values\n",
    "\n",
    "# Set the parameters for the train_test_split\n",
    "test_size=0.3\n",
    "seed=7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_predicted = model.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(Y_test, Y_predicted, digits=5) # digits cuántos decimales quieres.\n",
    "\n",
    "# Accuracy metric\n",
    "print(f'Accuracy {model.score(X_test, Y_test)*100:.5f}')\n",
    "print()\n",
    "print(report)\n",
    "\n",
    "print('------------------------------------------- CLASSIFICATION REPORT TOP50 ----------------------------------------------')\n",
    "# Classification Report \n",
    "\n",
    "# Imports (although already above, just for practice)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Select variables\n",
    "X = sg_data.iloc[:,2:8].values\n",
    "sg_data['Top10'] = sg_data['world_rank']<51 # changed this, copy-pasted the rest from classification report top10\n",
    "dicc={True:1,False:0}\n",
    "Y = sg_data['Top10'].replace(dicc)\n",
    "Y = Y.values\n",
    "\n",
    "# Set the parameters for the train_test_split\n",
    "test_size=0.3\n",
    "seed=7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_predicted = model.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(Y_test, Y_predicted, digits=5)\n",
    "\n",
    "# Accuracy metric\n",
    "print(f'Accuracy {model.score(X_test, Y_test)*100:.5f}')\n",
    "print()\n",
    "print(report)\n",
    "\n",
    "print()\n",
    "# DISCUSS DIFFERENCES (refer to next cell!!!!)\n",
    "print(\"Discussion of differences in the cell below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------\n",
    "-------------------------------------DISCUSS DIFFERENCES---------------------------------------------------------------------\n",
    "\n",
    "As expected, the ACCURACY of the logistic regression when predicting Top10 is higher than for Top50.\n",
    "The LOGLOSS obtained (more negative for Top50 than for Top10) indicates that the mistakes in the Top10 have been bigger/worse, than the mistaked when predicting the ones in the Top50. Since it is a metric that tells you that from the ones that from the failed predictions, for how much/how bad it has been.\n",
    "The AUC for the Top10 shows an incredible area of 1, which may seem impossible, but it is not if we check the CONFUSION MATRIX. AUC measures the ratio of FP (sensitivity), and since in this prediction (with this seed, etc.) I have 0 FP, the area is 1.\n",
    "The area for the Top50 is less than one and far above the 0.5 of the random curve, so it is fine.\n",
    "The CONFUSION MATRIX allows to check the number of TP, FP, FN and TN and the accuracy, which of course decreases from the Top10 prediction to the Top50 (because of the size of the dataset and the amount of predictions). Finally, the CLASSIFICATION REPORT provides more metrics that complement the analysis of the Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world_rank</th>\n",
       "      <th>university_name</th>\n",
       "      <th>country</th>\n",
       "      <th>teaching</th>\n",
       "      <th>international</th>\n",
       "      <th>research</th>\n",
       "      <th>citations</th>\n",
       "      <th>income</th>\n",
       "      <th>num_students</th>\n",
       "      <th>student_staff_ratio</th>\n",
       "      <th>international_students</th>\n",
       "      <th>female_male_ratio</th>\n",
       "      <th>year</th>\n",
       "      <th>females</th>\n",
       "      <th>males</th>\n",
       "      <th>ratio_male_to_female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>California Institute of Technology</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>97.7</td>\n",
       "      <td>54.6</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>83.7</td>\n",
       "      <td>2243.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.27</td>\n",
       "      <td>33 : 67</td>\n",
       "      <td>2011</td>\n",
       "      <td>33.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>97.8</td>\n",
       "      <td>82.3</td>\n",
       "      <td>91.4</td>\n",
       "      <td>99.9</td>\n",
       "      <td>87.5</td>\n",
       "      <td>11074.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>37 : 63</td>\n",
       "      <td>2011</td>\n",
       "      <td>37.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.702703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>98.3</td>\n",
       "      <td>29.5</td>\n",
       "      <td>98.1</td>\n",
       "      <td>99.2</td>\n",
       "      <td>64.3</td>\n",
       "      <td>15596.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.22</td>\n",
       "      <td>42 : 58</td>\n",
       "      <td>2011</td>\n",
       "      <td>42.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>90.5</td>\n",
       "      <td>77.7</td>\n",
       "      <td>94.1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>18812.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>46 : 54</td>\n",
       "      <td>2011</td>\n",
       "      <td>46.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>University of Oxford</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>88.2</td>\n",
       "      <td>77.2</td>\n",
       "      <td>93.9</td>\n",
       "      <td>95.1</td>\n",
       "      <td>73.5</td>\n",
       "      <td>19919.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.34</td>\n",
       "      <td>46 : 54</td>\n",
       "      <td>2011</td>\n",
       "      <td>46.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.173913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   world_rank                        university_name  \\\n",
       "1         2.0     California Institute of Technology   \n",
       "2         3.0  Massachusetts Institute of Technology   \n",
       "3         4.0                    Stanford University   \n",
       "5         6.0                University of Cambridge   \n",
       "6         6.0                   University of Oxford   \n",
       "\n",
       "                    country  teaching  international  research  citations  \\\n",
       "1  United States of America      97.7           54.6      98.0       99.9   \n",
       "2  United States of America      97.8           82.3      91.4       99.9   \n",
       "3  United States of America      98.3           29.5      98.1       99.2   \n",
       "5            United Kingdom      90.5           77.7      94.1       94.0   \n",
       "6            United Kingdom      88.2           77.2      93.9       95.1   \n",
       "\n",
       "   income  num_students  student_staff_ratio  international_students  \\\n",
       "1    83.7        2243.0                  6.9                    0.27   \n",
       "2    87.5       11074.0                  9.0                    0.33   \n",
       "3    64.3       15596.0                  7.8                    0.22   \n",
       "5    57.0       18812.0                 11.8                    0.34   \n",
       "6    73.5       19919.0                 11.6                    0.34   \n",
       "\n",
       "  female_male_ratio  year  females  males  ratio_male_to_female  \n",
       "1           33 : 67  2011     33.0   67.0              2.030303  \n",
       "2           37 : 63  2011     37.0   63.0              1.702703  \n",
       "3           42 : 58  2011     42.0   58.0              1.380952  \n",
       "5           46 : 54  2011     46.0   54.0              1.173913  \n",
       "6           46 : 54  2011     46.0   54.0              1.173913  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------- ACCURACY ------------------------------------------------------------\n",
      "------------------------------------------- ACCURACY TOP10 ------------------------------------------------------\n",
      "Logistic regression TOP10, k-fold 10 - Accuracy 94.292% (9.137%)\n",
      "------------------------------------------- ACCURACY TOP50 ------------------------------------------------------\n",
      "Logistic regression TOP10, k-fold 10 - Accuracy 91.767% (9.613%)\n",
      "\n",
      "------------------------------------------- LOGLOSS ------------------------------------------------------------\n",
      "------------------------------------------- LOGLOSS TOP10 ------------------------------------------------------\n",
      "Logistic regression, k-fold 4 - Logloss -0.269 (0.249)\n",
      "------------------------------------------- LOGLOSS TOP50 ------------------------------------------------------\n",
      "Logistic regression, k-fold 4 - Logloss -0.285 (0.198)\n",
      "\n",
      "------------------------------------------- AUC ------------------------------------------------------------\n",
      "------------------------------------------- AUC TOP10 ------------------------------------------------------\n",
      "Logistic regression, k-fold 4 - AUC 0.795 (0.166)\n",
      "------------------------------------------- AUC TOP50 ------------------------------------------------------\n",
      "Logistic regression, k-fold 4 - AUC 0.871 (0.086)\n",
      "\n",
      "------------------------------------------- CONFUSION MATRIX --------------------------------------------------------\n",
      "------------------------------------------- CONFUSION MATRIX TOP10 --------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[613   1]\n",
      " [ 36   3]]\n",
      "\n",
      "Accuracy 94.33384\n",
      "Accuracy check with conf. matrix 94.33384\n",
      "------------------------------------------- CONFUSION MATRIX TOP50 --------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[550   8]\n",
      " [ 37  58]]\n",
      "\n",
      "Accuracy 93.10873\n",
      "Accuracy check with conf. matrix 93.10873\n",
      "\n",
      "------------------------------------------- CLASSIFICATION REPORT ----------------------------------------------------\n",
      "------------------------------------------- CLASSIFICATION REPORT TOP10 ----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 94.33384\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.94453   0.99837   0.97070       614\n",
      "           1    0.75000   0.07692   0.13953        39\n",
      "\n",
      "    accuracy                        0.94334       653\n",
      "   macro avg    0.84727   0.53765   0.55512       653\n",
      "weighted avg    0.93291   0.94334   0.92106       653\n",
      "\n",
      "------------------------------------------- CLASSIFICATION REPORT TOP50 ----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 93.10873\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.93697   0.98566   0.96070       558\n",
      "           1    0.87879   0.61053   0.72050        95\n",
      "\n",
      "    accuracy                        0.93109       653\n",
      "   macro avg    0.90788   0.79809   0.84060       653\n",
      "weighted avg    0.92850   0.93109   0.92575       653\n",
      "\n",
      "\n",
      "Discussion of differences in the cell below\n"
     ]
    }
   ],
   "source": [
    "# B) Same for the Times ranking. \n",
    "# ... We will use our predictions for top-10 and top-50 the Times Dataset \n",
    "#... and evaluate accuracy, logloss, AUC, confusion matrix and classification report. Briefly discuss the diferences. \n",
    "\n",
    "\n",
    "# Import dataset and do corresponding adjustments. (copy-pasted from the 'Feature Selection' notebook)\n",
    "times = pd.read_csv('timesData.csv')\n",
    "times.world_rank.replace('=.','.', regex=True, inplace=True)\n",
    "times['world_rank'] = times['world_rank'].str.split('-').str.get(0).astype(float)\n",
    "times.world_rank = pd.to_numeric(times.world_rank, errors='coerce')\n",
    "times.dropna(subset=['world_rank'], axis=0, inplace=True) # DROPNA only of 'world_rank'\n",
    "times.international = pd.to_numeric(times.international, errors='coerce')\n",
    "times.income = pd.to_numeric(times.income, errors='coerce')\n",
    "times.num_students.replace('\\D','', regex=True, inplace=True)\n",
    "times.num_students = pd.to_numeric(times.num_students, errors='coerce')\n",
    "times.international_students.replace('\\D','', regex=True, inplace=True)\n",
    "times.international_students = pd.to_numeric(times.international_students, errors='coerce')\n",
    "times.international_students = times.international_students/100\n",
    "times['females'] = times.female_male_ratio.str.split(':').str.get(0) # manipulate so I can use the data of this column.\n",
    "times['males'] = times.female_male_ratio.str.split(':').str.get(1)\n",
    "times.females = pd.to_numeric(times.females, errors='coerce')\n",
    "times.males = pd.to_numeric(times.males, errors='coerce')\n",
    "times['ratio_male_to_female'] = times.males/times.females\n",
    "times.drop(columns='total_score',inplace=True)\n",
    "times.dropna(inplace=True)\n",
    "times.head()\n",
    "\n",
    "print('------------------------------------------- ACCURACY ------------------------------------------------------------')\n",
    "print('------------------------------------------- ACCURACY TOP10 ------------------------------------------------------')\n",
    "\n",
    "# Imports (although not necessary because they have already been imported previously in this notebook)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Select input and target variables and transform to numpy arrays.\n",
    "X = pd.concat([times.iloc[:,3:11],times['ratio_male_to_female']],axis=1).values\n",
    "times['Top10'] = times['world_rank']<11\n",
    "Y = times['Top10'].values\n",
    "\n",
    "# KFold\n",
    "splits=10\n",
    "kfold=KFold(n_splits=splits, random_state=7)\n",
    "\n",
    "#Logistic regression\n",
    "scoring=\"accuracy\"\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Obtain the performance measure - accuracy\n",
    "results = cross_val_score(model, X, Y, scoring=scoring, cv=kfold)\n",
    "\n",
    "#Show results\n",
    "print(f'Logistic regression TOP10, k-fold {splits:d} - Accuracy {results.mean()*100:5.3f}% ({results.std()*100:5.3f}%)')\n",
    "\n",
    "print('------------------------------------------- ACCURACY TOP50 ------------------------------------------------------')\n",
    "\n",
    "# Imports (although not necessary because they have already been imported previously in this notebook)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Select input and target variables and transform to numpy arrays.(same as before)\n",
    "X = pd.concat([times.iloc[:,3:11],times['ratio_male_to_female']],axis=1).values\n",
    "times['Top10'] = times['world_rank']<51 # changed from 'Accuracy top10', the rest copy-pasted\n",
    "Y = times['Top10'].values\n",
    "\n",
    "# KFold\n",
    "splits=10\n",
    "kfold=KFold(n_splits=splits, random_state=7)\n",
    "\n",
    "#Logistic regression\n",
    "scoring=\"accuracy\"\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Obtain the performance measure - accuracy\n",
    "results = cross_val_score(model, X, Y, scoring=scoring, cv=kfold)\n",
    "\n",
    "#Show results\n",
    "print(f'Logistic regression TOP10, k-fold {splits:d} - Accuracy {results.mean()*100:5.3f}% ({results.std()*100:5.3f}%)')\n",
    "\n",
    "print()\n",
    "\n",
    "print('------------------------------------------- LOGLOSS ------------------------------------------------------------')\n",
    "print('------------------------------------------- LOGLOSS TOP10 ------------------------------------------------------')\n",
    "# Imports and KFold (not necessary, because it is already above)\n",
    "# KFold\n",
    "splits=4 # I am using less than 10 folds, otherwise impacted because I am doing top10, then the first is all 1, the rest 0.\n",
    "#el número de splits tiene que ser divisible por el número de casos, hecho len(Y) y sí es posible entre 2\n",
    "# divido en 4 el data set, tengo el 25% en cada uno.\n",
    "kfold=KFold(n_splits=splits, random_state=6)\n",
    "# Select input and target variables and transform to numpy arrays.\n",
    "X = pd.concat([times.iloc[:,3:11],times['ratio_male_to_female']],axis=1).values\n",
    "times['Top10'] = times['world_rank']<11 # changed from 'Accuracy top10', the rest copy-pasted\n",
    "dicc={True:1,False:0}\n",
    "Y = times['Top10'].replace(dicc)\n",
    "Y = Y.values\n",
    "\n",
    "#Logistic regression\n",
    "scoring=\"neg_log_loss\" \n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Obtain the performance measure - accuracy ;; I ws trying with try/except until I got the result. \n",
    "# I leave it here as a reminder for me of how it is done.\n",
    "try:\n",
    "    results = cross_val_score(model, X, Y, scoring=scoring, cv=kfold)\n",
    "\n",
    "    # Show\n",
    "    print(f'Logistic regression, k-fold {splits:d} - Logloss {results.mean():5.3f} ({results.std():5.3f})')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print('------------------------------------------- LOGLOSS TOP50 ------------------------------------------------------')\n",
    "# Imports and KFold (not necessary, because it is already above)\n",
    "# KFold\n",
    "splits=4 # I am using less than 10 folds, otherwise impacted because I am doing top10, then the first is all 1, the rest 0.\n",
    "#el número de splits tiene que ser divisible por el número de casos, hecho len(Y) y sí es posible entre 2\n",
    "# divido en 4 el data set, tengo el 25% en cada uno.\n",
    "kfold=KFold(n_splits=splits, random_state=6)\n",
    "# Select input and target variables and transform to numpy arrays.\n",
    "X = pd.concat([times.iloc[:,3:11],times['ratio_male_to_female']],axis=1).values\n",
    "times['Top10'] = times['world_rank']<51 # changed from 'Accuracy top10', the rest copy-pasted\n",
    "dicc={True:1,False:0}\n",
    "Y = times['Top10'].replace(dicc)\n",
    "Y = Y.values\n",
    "\n",
    "#Logistic regression\n",
    "scoring=\"neg_log_loss\" \n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Obtain the performance measure - accuracy \n",
    "results = cross_val_score(model, X, Y, scoring=scoring, cv=kfold)\n",
    "\n",
    "# Show\n",
    "print(f'Logistic regression, k-fold {splits:d} - Logloss {results.mean():5.3f} ({results.std():5.3f})')\n",
    "\n",
    "print()\n",
    "\n",
    "print('------------------------------------------- AUC ------------------------------------------------------------')\n",
    "print('------------------------------------------- AUC TOP10 ------------------------------------------------------')\n",
    "# Imports\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Select variables\n",
    "X = pd.concat([times.iloc[:,3:11],times['ratio_male_to_female']],axis=1).values\n",
    "times['Top10'] = times['world_rank']<11\n",
    "dicc={True:1,False:0}\n",
    "Y = times['Top10'].replace(dicc)\n",
    "Y = Y.values\n",
    "# KFold\n",
    "splits=4\n",
    "kfold=KFold(n_splits=splits, random_state=7)\n",
    "scoring=\"roc_auc\"\n",
    "#Logistic regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "# Obtain the performance measure - accuracy\n",
    "results = cross_val_score(model, X, Y, scoring=scoring, cv=KFold(n_splits=splits, random_state=7))\n",
    "\n",
    "print(f'Logistic regression, k-fold {splits:d} - AUC {results.mean():5.3f} ({results.std():5.3f})')\n",
    "\n",
    "print('------------------------------------------- AUC TOP50 ------------------------------------------------------')\n",
    "# Imports\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Select variables\n",
    "X = pd.concat([times.iloc[:,3:11],times['ratio_male_to_female']],axis=1).values\n",
    "times['Top10'] = times['world_rank']<51 #copy-pasted code from 'AUC TOP10' and just changed this value\n",
    "dicc={True:1,False:0}\n",
    "Y = times['Top10'].replace(dicc)\n",
    "Y = Y.values\n",
    "# KFold\n",
    "splits=4\n",
    "kfold=KFold(n_splits=splits, random_state=7)\n",
    "scoring=\"roc_auc\"\n",
    "#Logistic regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "# Obtain the performance measure - accuracy\n",
    "results = cross_val_score(model, X, Y, scoring=scoring, cv=KFold(n_splits=splits, random_state=7))\n",
    "\n",
    "print(f'Logistic regression, k-fold {splits:d} - AUC {results.mean():5.3f} ({results.std():5.3f})')\n",
    "\n",
    "print()\n",
    "print('------------------------------------------- CONFUSION MATRIX --------------------------------------------------------')\n",
    "print('------------------------------------------- CONFUSION MATRIX TOP10 --------------------------------------------------')\n",
    "# Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Select variables (not necessary since I have them defined above, but to practice)\n",
    "X = pd.concat([times.iloc[:,3:11],times['ratio_male_to_female']],axis=1).values\n",
    "times['Top10'] = times['world_rank']<11 \n",
    "dicc={True:1,False:0}\n",
    "Y = times['Top10'].replace(dicc)\n",
    "Y = Y.values\n",
    "\n",
    "# Select arguments, split the data, log regression, confusion matrix\n",
    "test_size=0.3\n",
    "seed=7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, Y_train)\n",
    "Y_predicted = model.predict(X_test)\n",
    "c_matrix=confusion_matrix(Y_test, Y_predicted)\n",
    "\n",
    "# Show\n",
    "print(\"Confusion Matrix\")\n",
    "print(c_matrix)\n",
    "\n",
    "print()\n",
    "print(f'Accuracy {model.score(X_test, Y_test)*100:.5f}') # esto automáticamente ya te hace accuracy\n",
    "print(f'Accuracy check with conf. matrix {(c_matrix[0,0]+c_matrix[1,1])/c_matrix.sum()*100:.5f}') # aquí lo haces a mano.\n",
    "\n",
    "print('------------------------------------------- CONFUSION MATRIX TOP50 --------------------------------------------------')\n",
    "# Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Select variables (not necessary since I have them defined above, but to practice)\n",
    "X = pd.concat([times.iloc[:,3:11],times['ratio_male_to_female']],axis=1).values\n",
    "times['Top10'] = times['world_rank']<51 #copy-pasted code from 'Confusion Matrix TOP10' and just changed this value\n",
    "dicc={True:1,False:0}\n",
    "Y = times['Top10'].replace(dicc)\n",
    "Y = Y.values\n",
    "\n",
    "# Select arguments, split the data, log regression, confusion matrix\n",
    "test_size=0.3\n",
    "seed=7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, Y_train)\n",
    "Y_predicted = model.predict(X_test)\n",
    "c_matrix=confusion_matrix(Y_test, Y_predicted)\n",
    "\n",
    "# Show\n",
    "print(\"Confusion Matrix\")\n",
    "print(c_matrix)\n",
    "\n",
    "print()\n",
    "print(f'Accuracy {model.score(X_test, Y_test)*100:.5f}') # esto automáticamente ya te hace accuracy\n",
    "print(f'Accuracy check with conf. matrix {(c_matrix[0,0]+c_matrix[1,1])/c_matrix.sum()*100:.5f}') # aquí lo haces a mano.\n",
    "\n",
    "print()\n",
    "print('------------------------------------------- CLASSIFICATION REPORT ----------------------------------------------------')\n",
    "print('------------------------------------------- CLASSIFICATION REPORT TOP10 ----------------------------------------------')\n",
    "# Classification Report \n",
    "\n",
    "# Imports (although already above, just for practice)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Select variables\n",
    "X = pd.concat([times.iloc[:,3:11],times['ratio_male_to_female']],axis=1).values\n",
    "times['Top10'] = times['world_rank']<11 \n",
    "dicc={True:1,False:0}\n",
    "Y = times['Top10'].replace(dicc)\n",
    "Y = Y.values\n",
    "\n",
    "# Set the parameters for the train_test_split\n",
    "test_size=0.3\n",
    "seed=7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_predicted = model.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(Y_test, Y_predicted, digits=5) # digits cuántos decimales quieres.\n",
    "\n",
    "# Accuracy metric\n",
    "print(f'Accuracy {model.score(X_test, Y_test)*100:.5f}')\n",
    "print()\n",
    "print(report)\n",
    "\n",
    "print('------------------------------------------- CLASSIFICATION REPORT TOP50 ----------------------------------------------')\n",
    "# Classification Report \n",
    "\n",
    "# Imports (although already above, just for practice)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Select variables\n",
    "X = pd.concat([times.iloc[:,3:11],times['ratio_male_to_female']],axis=1).values\n",
    "times['Top10'] = times['world_rank']<51 # copy-pasted from 'Classification Report TOP10', just changed this value\n",
    "dicc={True:1,False:0}\n",
    "Y = times['Top10'].replace(dicc)\n",
    "Y = Y.values\n",
    "\n",
    "# Set the parameters for the train_test_split\n",
    "test_size=0.3\n",
    "seed=7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_predicted = model.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(Y_test, Y_predicted, digits=5)\n",
    "\n",
    "# Accuracy metric\n",
    "print(f'Accuracy {model.score(X_test, Y_test)*100:.5f}')\n",
    "print()\n",
    "print(report)\n",
    "\n",
    "print()\n",
    "# DISCUSS DIFFERENCES (refer to next cell!!!!)\n",
    "print(\"Discussion of differences in the cell below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------\n",
    "-------------------------------------DISCUSS DIFFERENCES---------------------------------------------------------------------\n",
    "\n",
    "As expected, the ACCURACY of the logistic regression when predicting Top10 (94%) is higher than for Top50 (91%), and the standard deviation for this dataset is greater than for the Shanghai one, although the difference betweetn standard deviations  is lower in this case (in relative terms).\n",
    "The LOGLOSS obtained are quite similar, although is seems that the failed predictions in the Top10 are better than the ones of the Top50 (which are less negative, therefore the logarithm of the sum is closer to one instead of zero.\n",
    "The AUC in this case is greater for the TOP50, and for this case it also presents a lower standard deviation. Still, both AUC far above the random curve and close to one.\n",
    "The CONFUSION MATRIX shows that the accuracy in the case of the Top10 (94%) has been slightly better than for the Top50 (93%), and the CLASSIFICATION REPORT provides additional metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2174"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> REGRESSION METRICS </h1>\n",
    "\n",
    "We will review the three most common regression metrics,\n",
    "<blockquote>\n",
    "1) Mean Absolute Error (MAE).\n",
    "<br>\n",
    "2) Mean Square Error (MSE).\n",
    "<br>\n",
    "3) $R^2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"boston.jpg\" width=1024>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Boston-Dataset-char.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        B  LSTAT  MEDV  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90    NaN  36.2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.006,  18.   ,   2.31 , ...,  15.3  , 396.9  ,   4.98 ],\n",
       "       [  0.027,   0.   ,   7.07 , ...,  17.8  , 396.9  ,   9.14 ],\n",
       "       [  0.027,   0.   ,   7.07 , ...,  17.8  , 392.83 ,   4.03 ],\n",
       "       ...,\n",
       "       [  0.061,   0.   ,  11.93 , ...,  21.   , 396.9  ,   5.64 ],\n",
       "       [  0.11 ,   0.   ,  11.93 , ...,  21.   , 393.45 ,   6.48 ],\n",
       "       [  0.047,   0.   ,  11.93 , ...,  21.   , 396.9  ,   7.88 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1     2    3      4      5     6       7    8      9    10  \\\n",
       "0  0.00632  18.0  2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
       "1  0.02731   0.0  7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
       "2  0.02729   0.0  7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
       "3  0.03237   0.0  2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
       "4  0.06905   0.0  2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
       "\n",
       "       11    12  \n",
       "0  396.90  4.98  \n",
       "1  396.90  9.14  \n",
       "2  392.83  4.03  \n",
       "3  394.63  2.94  \n",
       "4  396.90  0.00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Boston Housing dataset and separate input and output components \n",
    "\n",
    "from numpy import set_printoptions\n",
    "set_printoptions(precision=3)\n",
    "\n",
    "filename=\"HousingData.csv\"\n",
    "b_housing=pd.read_csv(filename)\n",
    "b_housing.head()\n",
    "\n",
    "b_housing.fillna(0,inplace=True) # we have NaN\n",
    "\n",
    "# First we separate into input and output components\n",
    "array=b_housing.values\n",
    "X=array[:,0:13]\n",
    "Y=array[:,13]\n",
    "np.set_printoptions(suppress=True)\n",
    "X\n",
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Mean Absolute Error</h1>\n",
    "\n",
    "The MAE (Mean Absolute Error) is the sum of the absolute differences between the actual values and the predictions.\n",
    "\n",
    "It provides an idea of the magnitude of the error but not of its direction. A 0 indicates a perfect prediction and like logloss this metric is inverted by the cross_val_score() function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston Housing - Linear Regression, MAE: -3.975 (2.152)\n"
     ]
    }
   ],
   "source": [
    "# Mean Absolute Error\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# KFold\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "\n",
    "#model\n",
    "model = LinearRegression()\n",
    "\n",
    "scoring = \"neg_mean_absolute_error\"\n",
    "res = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "\n",
    "print(f'Boston Housing - Linear Regression, MAE: {res.mean():.3f} ({res.std():.3f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Mean Squared Error</h1>\n",
    "\n",
    "The idea of the MSE is the same of the MAE but we square the value in order to obtain always a positive value. Again, it provides an idea of the magnitude but not of the direction. \n",
    "\n",
    "Many times we use the RMSE (Root Mean Squared Error) in order to convert the units back to the original units of the output variable.   \n",
    "\n",
    "Again this metric is inverted so results are increasing (scores that should be minimized are presented as negative while the ones that should be maximized as positive). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston Housing - Linear Regression, MSE: -34.090 (44.046)\n",
      "Boston Housing - Linear Regression, MSE: 5.839 (6.637)\n"
     ]
    }
   ],
   "source": [
    "# Mean Squared Error\n",
    "\n",
    "import math \n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# KFold\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "\n",
    "#model\n",
    "model = LinearRegression()\n",
    "\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "res = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "\n",
    "print(f'Boston Housing - Linear Regression, MSE: {res.mean():.3f} ({res.std():.3f})')\n",
    "print(f'Boston Housing - Linear Regression, MSE: {math.sqrt(abs(res.mean())):.3f} ({math.sqrt(res.std()):.3f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>$R^2$</h1>\n",
    "\n",
    "The coefficient of determination $R^2$ provides an indication of the goodness of the predictions.\n",
    "\n",
    "It's a value of 0 and 1 for non-fit and perfect fit respectively. A value closer to 0 and less than 0.5 indicates a poor fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston Housing - Linear Regression, R2: 0.243 (0.573)\n"
     ]
    }
   ],
   "source": [
    "# R2\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# KFold\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "\n",
    "#model\n",
    "model = LinearRegression()\n",
    "\n",
    "scoring = \"r2\"\n",
    "res = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "\n",
    "print(f'Boston Housing - Linear Regression, R2: {res.mean():.3f} ({res.std():.3f})')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
