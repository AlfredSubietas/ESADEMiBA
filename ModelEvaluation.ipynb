{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "#sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "We need to evaluate the performance of our machine learning models because of two main reason. First to be able to tune them deciding which interventions increase their performance and which ones don't. And secondly to have concrete knowlodge on how accurate they are and therefore to what extent can we trust them. \n",
    "\n",
    "The first insight that we have to incorporate into our thinking of model evaluation is that by no means we can evaluate our model with the data that we used for training. Nowadays algorithms are very sophisticated and therefore prone to overfitting. It is therefore necessary to use new data, unseen by model, for its evaluation. \n",
    "\n",
    "There are two main approaches. One, the most obvious, is to divide the data in a training and test set. We train the model with the train set and we use the test set to evaluate it. It is simple and works well if we have lots of data. However, if data is scarce, then we don't have enough diversity in the data and the evaluation could not be very accurate. \n",
    "\n",
    "The second approach tries to solve this problem of evaluation, as accurate as we can, a model with a limited amount of data. As you can imagine, they consist on using sampling techniques with or without repetition in order to try to \"augment\" the amount of data available. \n",
    "\n",
    "Once we have chosen the best hyperparameters and have the model ready for production, we train it with the whole data and put it in operational use. \n",
    "\n",
    "We are going to look at four different techniques that we can use to split our data and create useful estimates of our models:\n",
    "\n",
    "        1) Train and test sets.\n",
    "        2) K-fold Cross-validation.\n",
    "        3) Leave one-out cross-validation.\n",
    "        4) Repeated random test-train splits.\n",
    "\n",
    "Yes, we will use the Pima Indians onset of diabetes dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Pima_indians_cowboy_1889.jpg\">\n",
    "\n",
    "In this exercise we will use one of the traditional Machine Learning dataset, the Pima Indians diabetes dataset.\n",
    "\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "Content\n",
    "The datasets consists of several medical predictor variables and one target variable, <b>Outcome</b>. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n",
    "<blockquote>\n",
    "        <ul style=\"list-style-type:square;\">\n",
    "            <li>Pregnancies</li> \n",
    "            <li>Glucose</li>\n",
    "            <li>BloodPressure</li>\n",
    "            <li>SkinThickness</li>\n",
    "            <li>Insulin</li>\n",
    "            <li>BMI</li>\n",
    "            <li>DiabetesPedigreeFunction (scores de likelihood of diabetes based on family history)</li>\n",
    "            <li>Age</li>\n",
    "            <li>Outcome</li>\n",
    "        </ul>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yo:\n",
    "\n",
    "You divide the data into TEST (the one you present) and TRAINING  (20%). Set of info.\n",
    "K-FOLD to present the model --> to see validation.\n",
    "data is separated in various chanks (e.g. 1-10)\n",
    "-first iteration = train 2-10 and test with 1\n",
    "second iteration train 1 & 3-10 and test with 2\n",
    "until all chunks are testes\n",
    "compare test results\n",
    "stdv of results (if stdv is high e.g. need to acquire new data.\n",
    "\n",
    "Problem:test can have bias.\n",
    "Multiple splits (not to be presented)\n",
    "Normally ten, bu if not enough data tehn 4 (std higher?)\n",
    "Look at std of results. If low, then trusted.\n",
    "Typical error --> have too many k-folds.\n",
    "\n",
    "You need a god chunk of data for training and test.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TEST AND SPLIT a variation is to randomize it. Imagine you have ten with random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1     2     3      4     5      6     7\n",
       "0  6.0  148.0  72.0  35.0    0.0  33.6  0.627  50.0\n",
       "1  1.0   85.0  66.0  29.0    0.0  26.6  0.351  31.0\n",
       "2  8.0  183.0  64.0   0.0    0.0  23.3  0.672  32.0\n",
       "3  1.0   89.0  66.0  23.0   94.0  28.1  0.167  21.0\n",
       "4  0.0  137.0  40.0  35.0  168.0  43.1  2.288  33.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Pima indians dataset and separate input and output components \n",
    "\n",
    "from numpy import set_printoptions\n",
    "set_printoptions(precision=3)\n",
    "\n",
    "filename=\"pima-indians-diabetes.data.csv\"\n",
    "names=[\"pregnancies\", \"glucose\", \"pressure\", \"skin\", \"insulin\", \"bmi\", \"pedi\", \"age\", \"outcome\"]\n",
    "p_indians=pd.read_csv(filename, names=names)\n",
    "p_indians.head()\n",
    "\n",
    "# First we separate into input and output components\n",
    "array=p_indians.values\n",
    "X=array[:,0:8]\n",
    "Y=array[:,8]\n",
    "X\n",
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Split into Train and Test Sets </h1>\n",
    "\n",
    "A simple idea and also probably the most commonly used approach is to split our data into two sets. Use one for training and the other for testing. Normally a 70% of the data is used for training and 30% for testing, but of course these are arbitrary numbers and anything can be (e.g. 80% - 20% if the dataset is large). \n",
    "\n",
    "The points in favor of this approach is that is simple and fast. It works well when datasets are large but also it is widely used as a first approximation. One important thing that must be taken into account is that the variance of both sets is similar, if not we can encounter unwanted surprises. \n",
    "\n",
    "The downside is that we can have meaninful differences is the differences in variance are high and we that we take an important risk when the amount of data is small. Once the model is in production we may find that its performance has little in common with what we tested because the data that it encounters is really different. \n",
    "\n",
    "The <b> train_test_split </b> module in scikit-learn is the one used for splitting the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 76.190\n"
     ]
    }
   ],
   "source": [
    "# Split into Train and Test Sets\n",
    "set_printoptions(precision=3)\n",
    "p_indians.head()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "# we need to make it reproducible, so we use a seed for the pseudo-random\n",
    "test_size=0.3\n",
    "seed = 7 # para que siempre me dé lo mismo. Para asegurar que sale mismo resultado que profesor.\n",
    "\n",
    "# the actual split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "# Let's do the log regresssion\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "\n",
    "# Now let's find the accurary with the test split\n",
    "result = model.score(X_test, Y_test) # lo haces con el test para ver si hay overfit.\n",
    "\n",
    "# print(model.score(X_train, Y_train)) -- train siempre error menor porque se ha entrenado con este número.\n",
    "# Si error del train y del test es similar vas por buen camino.\n",
    "print(f'Accuracy {result*100:5.3f}') # en porcentaje, tres decimales f de float, buscar el 5!!!!\n",
    "\n",
    "#f strings es la forma más rápida y convenient. \n",
    "\n",
    "\n",
    "# puedo definir test o train size pero no ambos porque son equivalentes.\n",
    "# liblinear es un algoritmo. Es para True o False y pequeño dataset, sino newton para tener múltiples opciones.\n",
    "# lbfgs es el default en vez de liblinear, para grandes o pequeños dfs. Multinomial loss, que no sea solo True or False.\n",
    "\n",
    "# Model score te da accuracy de la clasificación, es un porcentaje (algo dividido entre todo).\n",
    "# 95 % bien \n",
    "# 99% o tienes dependencia lineal o estás haciendo overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"red\" size=6>Mission 1</font>\n",
    "\n",
    "a) Change the distribution between Train and Test Sets. How does it affect accurarcy?\n",
    "<br><br>\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Test is 30 % of the data-------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with test 30 % 76.190\n",
      "-------------Test is 10 % of the data-------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with test 10 % 83.117\n",
      "-------------Test is 50 % of the data-------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with test 50 % 77.604\n",
      "-------------Test is 60 % of the data-------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with test 60 % 75.054\n"
     ]
    }
   ],
   "source": [
    "# A) Change the distribution between Train and Test Sets. How does it affect accurarcy? \n",
    "\n",
    "# Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "test_size=0.3\n",
    "seed = 7\n",
    "\n",
    "# Split, log regression and result for i % of data as test\n",
    "print(\"-------------Test is 30 % of the data-------------\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "result= model.score(X_test, Y_test)\n",
    "print(f'Accuracy with test 30 % {result*100:5.3f}')\n",
    "\n",
    "print(\"-------------Test is 10 % of the data-------------\")\n",
    "test_size=0.1\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "result= model.score(X_test, Y_test)\n",
    "print(f'Accuracy with test 10 % {result*100:5.3f}')\n",
    "\n",
    "print(\"-------------Test is 50 % of the data-------------\")\n",
    "test_size=0.5\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "result= model.score(X_test, Y_test)\n",
    "print(f'Accuracy with test 50 % {result*100:5.3f}')\n",
    "\n",
    "print(\"-------------Test is 60 % of the data-------------\")\n",
    "test_size=0.6\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "result= model.score(X_test, Y_test)\n",
    "print(f'Accuracy with test 60 % {result*100:5.3f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ¿¿¿DEBO RESPONDER A PREGUNTA TEÓRICA TAMBIÉN???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=k-fold.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train_test_split se hace aleatorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>K-fold Cross-Validation</h1>\n",
    "\n",
    "The objective of k-fold cross-validation is to reduce the variance that we encounter when using the train-test split approach. \n",
    "\n",
    "In this approach the available data is divided into k splits that are called folds (3, 5, 10 are common). We train and test the model k times. Each time we use k-1 folds for training and one fold for testing. Once we finish we use the mean of the evaluation measure together with its standard deviation as performance measure. \n",
    "\n",
    "Obviously the dataset must be large enough to accommodate the process. \n",
    "\n",
    "K-Fold Cross Validation uses the <b>KFold </b> class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression, k-fold 10 - Accuracy 76.951% (4.841%)\n"
     ]
    }
   ],
   "source": [
    "# K-fold Cross Validation\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "p_indians.head()\n",
    "\n",
    "# KFold\n",
    "splits=10\n",
    "kfold=KFold(n_splits=splits, random_state=7)\n",
    "\n",
    "#Logistic regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Obtain the performance measure - accuracy\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "#cv es \"cross validation model\"?\n",
    "\n",
    "print(f'Logistic regression, k-fold {splits:d} - Accuracy {results.mean()*100:5.3f}% ({results.std()*100:5.3f}%)')\n",
    "\n",
    "# random state es seed.\n",
    "# cv es la forma en que divides data.\n",
    "# buscar splits:d!!\n",
    "# te da 10 scores, accuracies. Quiero la media y std de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Leave One Out Cross-Validation</h1>\n",
    "\n",
    "What will happen if we take k-fold to the extreme? In this case we will have as many folds as points, so k will be equal to the number of points and the prediction will be done each time for the one point left. \n",
    "\n",
    "This is an effort to make the most reasonable estimate possible given a dataset, it's called leave one out cross validation. \n",
    "\n",
    "Obviously you pay a penalty in terms of computational expense and the standard deviation has more variance than with k-fold. \n",
    "\n",
    "For Leave One Out Cross-Validation you use the <b>LeaveOneOut</b> class. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yo:\n",
    "k-fold to extreme. the subset is only one. you test with one element\n",
    "loo = leave one out.\n",
    "\n",
    "Normally k-fold is good enough. k-fold is good, that is the summary.\n",
    "prof: play with the model changing values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression, Leave one out - Accuracy 76.823% (42.196%)\n"
     ]
    }
   ],
   "source": [
    "# Leave one out cross-validation \n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "p_indians.head()\n",
    "\n",
    "# Leave one out cross-validation\n",
    "loo=LeaveOneOut()\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "#  performance\n",
    "results = cross_val_score(model, X, Y, cv=loo)\n",
    "\n",
    "print(f'Logistic regression, Leave one out - Accuracy {results.mean()*100:5.3f}% ({results.std()*100:5.3f}%)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Repeated Random Test-Train Splits </h1>\n",
    "\n",
    "Another approach is to apply repeatedly a train-test split. This way takes advantage of the train-test speed and the reduction of variance of cross validation at the same time. \n",
    "\n",
    "A down side of the method is that we are including much of the same data, therefore results even if they look very nice, may not be realistic.\n",
    "\n",
    "For Repeated Random Test-Train Splits you use the <b>ShuffleSplit</b> class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yo:\n",
    "es un poco más de lo mismo. Repite el test 10 veces en este caso?\n",
    "profe suele imprimir table... 2stdv is 96%? shape normal curve.\n",
    "\n",
    "Normally you use train and split. \n",
    "boostng and bugging for artificiaylly augmenting the size of the sample if you don't have enough table.\n",
    "el modelo lo presentas con k-fold. primero lo haces con train and split para ver si sale... pero luego hace k-folds y eso es lo que presentas.\n",
    "similar a lo que se hace en deep learning.\n",
    "train with more data... increase accuracy. hasta cierto punto en el que ya se queda estable. con test data empieza y luego baja? buscar inflexion point. But normally you are not so sophisticated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Regression - Repeated Test-Train 10 - Accuracy 76.970% 1.366%\n"
     ]
    }
   ],
   "source": [
    "# Repeated Random Test-Train Splits\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "p_indians.head()\n",
    "\n",
    "nrepeat=10\n",
    "test_size=0.3\n",
    "seed=7\n",
    "\n",
    "shuffle=ShuffleSplit(n_splits=nrepeat, test_size=test_size, random_state=seed)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "res = cross_val_score(model, X, Y, cv=shuffle)\n",
    "\n",
    "print(f'Log Regression - Repeated Test-Train {nrepeat:d} - Accuracy {res.mean()*100:5.3f}% {res.std()*100:5.3f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Which one to use and When? </h1>\n",
    "\n",
    "First things first. K-fold is the gold-standard, if you are doing any serious work or presenting results to a digital educated audiende, please use k-fold and you'll avoid problems. \n",
    "\n",
    "Train and Test is ok, and it is used for common quick & dirty work. As you have observed in the exercices if the dataset is moderately large, the differences are small. Certainly you avoid surprises with repeatedly using train-test or much better k-fold and your last model should be evaluated always this way, but train and test split is ok for model selection and hyperparameter tunning. \n",
    "\n",
    "What about the rest? In all these techniques you try to balance accuracy in the estimated performance, evaluation speed and dataset size, they correspond to different bets in this balance. \n",
    "\n",
    "You don't know what to do ... The staple is k-fold with 10-cross-validation, start there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"red\" size=6>Mission 2</font>\n",
    "\n",
    "a) Using the Shangai Data and log regression for top-10, top-50 and top-100 evaluate the models with train-test split and k-fold-10.\n",
    "<br><br>\n",
    "b) Same for the data of the Times ranking. \n",
    "<br><br>\n",
    "\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world_rank</th>\n",
       "      <th>university_name</th>\n",
       "      <th>alumni</th>\n",
       "      <th>award</th>\n",
       "      <th>hici</th>\n",
       "      <th>ns</th>\n",
       "      <th>pub</th>\n",
       "      <th>pcp</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>72.4</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>99.8</td>\n",
       "      <td>93.4</td>\n",
       "      <td>53.3</td>\n",
       "      <td>56.6</td>\n",
       "      <td>70.9</td>\n",
       "      <td>66.9</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>41.1</td>\n",
       "      <td>72.2</td>\n",
       "      <td>88.5</td>\n",
       "      <td>70.9</td>\n",
       "      <td>72.3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>University of California, Berkeley</td>\n",
       "      <td>71.8</td>\n",
       "      <td>76.0</td>\n",
       "      <td>69.4</td>\n",
       "      <td>73.9</td>\n",
       "      <td>72.2</td>\n",
       "      <td>52.7</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Massachusetts Institute of Technology (MIT)</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.6</td>\n",
       "      <td>66.7</td>\n",
       "      <td>65.8</td>\n",
       "      <td>64.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   world_rank                              university_name  alumni  award  \\\n",
       "0         1.0                           Harvard University   100.0  100.0   \n",
       "1         2.0                      University of Cambridge    99.8   93.4   \n",
       "2         3.0                          Stanford University    41.1   72.2   \n",
       "3         4.0           University of California, Berkeley    71.8   76.0   \n",
       "4         5.0  Massachusetts Institute of Technology (MIT)    74.0   80.6   \n",
       "\n",
       "    hici     ns    pub   pcp  year  \n",
       "0  100.0  100.0  100.0  72.4  2005  \n",
       "1   53.3   56.6   70.9  66.9  2005  \n",
       "2   88.5   70.9   72.3  65.0  2005  \n",
       "3   69.4   73.9   72.2  52.7  2005  \n",
       "4   66.7   65.8   64.3  53.0  2005  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------Train-test split TOP10------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for TOP10 99.727\n",
      "-----------------------------Train-test split TOP50------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for TOP50 98.770\n",
      "-----------------------------Train-test split TOP100------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for TOP100 98.565\n",
      "-----------------------------K-FOLD TOP10------------------------------------\n",
      "Logistic regression TOP10, k-fold 10 - Accuracy 99.836% (0.179%)\n",
      "-----------------------------K-FOLD TOP50------------------------------------\n",
      "Logistic regression TOP50, k-fold 10 - Accuracy 98.687% (0.307%)\n",
      "-----------------------------K-FOLD TOP100------------------------------------\n",
      "Logistic regression TOP100, k-fold 10 - Accuracy 98.358% (0.610%)\n"
     ]
    }
   ],
   "source": [
    "# A) Using the Shanghai Data and log regression for top-10, top-50 and top-100 evaluate the models with train-test split \n",
    "# ...and k-fold-10. \n",
    "\n",
    "# Import dataset (copy-pasted from the 'Feature Selection' notebook missions)\n",
    "sg_data = pd.read_csv('shanghaiData.csv')\n",
    "sg_data['world_rank'] = sg_data['world_rank'].str.split('-').str.get(0).astype(float)\n",
    "sg_data.drop(columns=['national_rank','total_score'], inplace=True)\n",
    "sg_data.dropna(inplace=True)\n",
    "sg_data.head()\n",
    "\n",
    "print('-----------------------------Train-test split TOP10------------------------------------')\n",
    "# Select input and target variables with iloc (integer position-based) and transform to numpy arrays.\n",
    "X = sg_data.iloc[:,2:8].values\n",
    "sg_data['Top10'] = sg_data['world_rank']<11\n",
    "Y = sg_data['Top10'].values\n",
    "\n",
    "# Specific imports, log regression and accuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "test_size=0.3 \n",
    "seed = 7 # to reproduce\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "result = model.score(X_test, Y_test) # find accuracy\n",
    "\n",
    "print(f'Accuracy for TOP10 {result*100:5.3f}') \n",
    "\n",
    "print('-----------------------------Train-test split TOP50------------------------------------')\n",
    "# Select input and target variables with iloc (integer position-based) and transform to numpy arrays.\n",
    "X = sg_data.iloc[:,2:8].values\n",
    "sg_data['Top50'] = sg_data['world_rank']<51\n",
    "Y = sg_data['Top50'].values\n",
    "\n",
    "#  Specific imports, log regression and accuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "test_size=0.3 \n",
    "seed = 7 # to reproduce\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "result = model.score(X_test, Y_test) # find accuracy\n",
    "\n",
    "print(f'Accuracy for TOP50 {result*100:5.3f}') \n",
    "\n",
    "print('-----------------------------Train-test split TOP100------------------------------------')\n",
    "# Select input and target variables with iloc (integer position-based) and transform to numpy arrays.\n",
    "X = sg_data.iloc[:,2:8].values\n",
    "sg_data['Top100'] = sg_data['world_rank']<101\n",
    "Y = sg_data['Top100'].values\n",
    "\n",
    "#  Specific imports, log regression and accuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "test_size=0.3 \n",
    "seed = 7 # to reproduce\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "result = model.score(X_test, Y_test) # find accuracy\n",
    "\n",
    "print(f'Accuracy for TOP100 {result*100:5.3f}')\n",
    "\n",
    "\n",
    "\n",
    "print('-----------------------------K-FOLD TOP10------------------------------------')\n",
    "\n",
    "# Imports\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# KFold\n",
    "splits=10\n",
    "kfold=KFold(n_splits=splits, random_state=7)\n",
    "\n",
    "# Select input and target variables and transform to numpy arrays.\n",
    "X = sg_data.iloc[:,2:8].values\n",
    "sg_data['Top10'] = sg_data['world_rank']<11\n",
    "Y = sg_data['Top10'].values\n",
    "\n",
    "#Logistic regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Obtain the performance measure - accuracy\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "#Show results\n",
    "print(f'Logistic regression TOP10, k-fold {splits:d} - Accuracy {results.mean()*100:5.3f}% ({results.std()*100:5.3f}%)')\n",
    "\n",
    "\n",
    "print('-----------------------------K-FOLD TOP50------------------------------------')\n",
    "\n",
    "# Imports\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# KFold\n",
    "splits=10\n",
    "kfold=KFold(n_splits=splits, random_state=7)\n",
    "\n",
    "# Select input and target variables and transform to numpy arrays.\n",
    "X = sg_data.iloc[:,2:8].values\n",
    "sg_data['Top50'] = sg_data['world_rank']<51 # not necessary since I have it for the train-test split already, but pretend not.\n",
    "Y = sg_data['Top50'].values\n",
    "\n",
    "#Logistic regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Obtain the performance measure - accuracy\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "#Show results\n",
    "print(f'Logistic regression TOP50, k-fold {splits:d} - Accuracy {results.mean()*100:5.3f}% ({results.std()*100:5.3f}%)')\n",
    "\n",
    "\n",
    "print('-----------------------------K-FOLD TOP100------------------------------------')\n",
    "\n",
    "# Imports\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# KFold\n",
    "splits=10\n",
    "kfold=KFold(n_splits=splits, random_state=7)\n",
    "\n",
    "# Select input and target variables and transform to numpy arrays.\n",
    "X = sg_data.iloc[:,2:8].values\n",
    "sg_data['Top100'] = sg_data['world_rank']<101 # not necessary since I have it for the train-test split already, but pretend not.\n",
    "Y = sg_data['Top100'].values\n",
    "\n",
    "#Logistic regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Obtain the performance measure - accuracy\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "#Show results\n",
    "print(f'Logistic regression TOP100, k-fold {splits:d} - Accuracy {results.mean()*100:5.3f}% ({results.std()*100:5.3f}%)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world_rank</th>\n",
       "      <th>university_name</th>\n",
       "      <th>country</th>\n",
       "      <th>teaching</th>\n",
       "      <th>international</th>\n",
       "      <th>research</th>\n",
       "      <th>citations</th>\n",
       "      <th>income</th>\n",
       "      <th>num_students</th>\n",
       "      <th>student_staff_ratio</th>\n",
       "      <th>international_students</th>\n",
       "      <th>female_male_ratio</th>\n",
       "      <th>year</th>\n",
       "      <th>females</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>California Institute of Technology</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>97.7</td>\n",
       "      <td>54.6</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>83.7</td>\n",
       "      <td>2243.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.27</td>\n",
       "      <td>33 : 67</td>\n",
       "      <td>2011</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>97.8</td>\n",
       "      <td>82.3</td>\n",
       "      <td>91.4</td>\n",
       "      <td>99.9</td>\n",
       "      <td>87.5</td>\n",
       "      <td>11074.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>37 : 63</td>\n",
       "      <td>2011</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>98.3</td>\n",
       "      <td>29.5</td>\n",
       "      <td>98.1</td>\n",
       "      <td>99.2</td>\n",
       "      <td>64.3</td>\n",
       "      <td>15596.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.22</td>\n",
       "      <td>42 : 58</td>\n",
       "      <td>2011</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>90.5</td>\n",
       "      <td>77.7</td>\n",
       "      <td>94.1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>18812.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>46 : 54</td>\n",
       "      <td>2011</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>University of Oxford</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>88.2</td>\n",
       "      <td>77.2</td>\n",
       "      <td>93.9</td>\n",
       "      <td>95.1</td>\n",
       "      <td>73.5</td>\n",
       "      <td>19919.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.34</td>\n",
       "      <td>46 : 54</td>\n",
       "      <td>2011</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   world_rank                        university_name  \\\n",
       "1         2.0     California Institute of Technology   \n",
       "2         3.0  Massachusetts Institute of Technology   \n",
       "3         4.0                    Stanford University   \n",
       "5         6.0                University of Cambridge   \n",
       "6         6.0                   University of Oxford   \n",
       "\n",
       "                    country  teaching  international  research  citations  \\\n",
       "1  United States of America      97.7           54.6      98.0       99.9   \n",
       "2  United States of America      97.8           82.3      91.4       99.9   \n",
       "3  United States of America      98.3           29.5      98.1       99.2   \n",
       "5            United Kingdom      90.5           77.7      94.1       94.0   \n",
       "6            United Kingdom      88.2           77.2      93.9       95.1   \n",
       "\n",
       "   income  num_students  student_staff_ratio  international_students  \\\n",
       "1    83.7        2243.0                  6.9                    0.27   \n",
       "2    87.5       11074.0                  9.0                    0.33   \n",
       "3    64.3       15596.0                  7.8                    0.22   \n",
       "5    57.0       18812.0                 11.8                    0.34   \n",
       "6    73.5       19919.0                 11.6                    0.34   \n",
       "\n",
       "  female_male_ratio  year  females  \n",
       "1           33 : 67  2011     33.0  \n",
       "2           37 : 63  2011     37.0  \n",
       "3           42 : 58  2011     42.0  \n",
       "5           46 : 54  2011     46.0  \n",
       "6           46 : 54  2011     46.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------Train-test split TOP10------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for TOP10 94.793\n",
      "-----------------------------Train-test split TOP50------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for TOP50 92.649\n",
      "-----------------------------Train-test split TOP100------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for TOP100 88.821\n",
      "-----------------------------K-FOLD TOP10------------------------------------\n",
      "Logistic regression TOP10, k-fold 10 - Accuracy 94.063% (9.043%)\n",
      "-----------------------------K-FOLD TOP50------------------------------------\n",
      "Logistic regression TOP50, k-fold 10 - Accuracy 92.776% (9.568%)\n",
      "-----------------------------K-FOLD TOP100------------------------------------\n",
      "Logistic regression TOP100, k-fold 10 - Accuracy 88.368% (10.026%)\n"
     ]
    }
   ],
   "source": [
    "# B) Same for the data of the Times ranking. \n",
    "\n",
    "# I copy-paste the code of my previous notebook.\n",
    "# Import dataset and do corresponding adjustments.\n",
    "times = pd.read_csv('timesData.csv')\n",
    "times.world_rank.replace('=.','.', regex=True, inplace=True)\n",
    "times['world_rank'] = times['world_rank'].str.split('-').str.get(0).astype(float)\n",
    "times.world_rank = pd.to_numeric(times.world_rank, errors='coerce')\n",
    "times.dropna(subset=['world_rank'], axis=0, inplace=True)\n",
    "times.international = pd.to_numeric(times.international, errors='coerce')\n",
    "times.income = pd.to_numeric(times.income, errors='coerce')\n",
    "times.num_students.replace('\\D','', regex=True, inplace=True)\n",
    "times.num_students = pd.to_numeric(times.num_students, errors='coerce')\n",
    "times.international_students.replace('\\D','', regex=True, inplace=True)\n",
    "times.international_students = pd.to_numeric(times.international_students, errors='coerce')\n",
    "times.international_students = times.international_students/100\n",
    "times['females'] = times.female_male_ratio.str.split(':').str.get(0)\n",
    "times.females = pd.to_numeric(times.females, errors='coerce')\n",
    "times.drop(columns='total_score',inplace=True)\n",
    "times.dropna(inplace=True)\n",
    "times.head()\n",
    "\n",
    "\n",
    "print('-----------------------------Train-test split TOP10------------------------------------')\n",
    "\n",
    "# Select input and target variables and transform to numpy arrays.\n",
    "X = pd.concat([times.iloc[:,3:11],times['females']],axis=1).values\n",
    "times['Top10'] = times['world_rank']<11\n",
    "Y = times['Top10'].values\n",
    "\n",
    "# Specific imports, log regression and accuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "test_size=0.3 \n",
    "seed = 7 # to reproduce\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "result = model.score(X_test, Y_test) # find accuracy\n",
    "\n",
    "print(f'Accuracy for TOP10 {result*100:5.3f}') \n",
    "\n",
    "print('-----------------------------Train-test split TOP50------------------------------------')\n",
    "\n",
    "# Select input and target variables and transform to numpy arrays.\n",
    "X = pd.concat([times.iloc[:,3:11],times['females']],axis=1).values\n",
    "times['Top50'] = times['world_rank']<51\n",
    "Y = times['Top50'].values\n",
    "\n",
    "# Specific imports, log regression and accuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "test_size=0.3 \n",
    "seed = 7 # to reproduce\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "result = model.score(X_test, Y_test) # find accuracy\n",
    "\n",
    "print(f'Accuracy for TOP50 {result*100:5.3f}') \n",
    "\n",
    "print('-----------------------------Train-test split TOP100------------------------------------')\n",
    "\n",
    "# Select input and target variables and transform to numpy arrays.\n",
    "X = pd.concat([times.iloc[:,3:11],times['females']],axis=1).values\n",
    "times['Top100'] = times['world_rank']<101\n",
    "Y = times['Top100'].values\n",
    "\n",
    "# Specific imports, log regression and accuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "test_size=0.3 \n",
    "seed = 7 # to reproduce\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "result = model.score(X_test, Y_test) # find accuracy\n",
    "\n",
    "print(f'Accuracy for TOP100 {result*100:5.3f}') \n",
    "\n",
    "\n",
    "print('-----------------------------K-FOLD TOP10------------------------------------')\n",
    "\n",
    "# Select input and target variables and transform to numpy arrays.\n",
    "X = pd.concat([times.iloc[:,3:11],times['females']],axis=1).values\n",
    "times['Top10'] = times['world_rank']<11\n",
    "Y = times['Top10'].values\n",
    "\n",
    "# Imports\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# KFold\n",
    "splits=10\n",
    "kfold=KFold(n_splits=splits, random_state=7)\n",
    "\n",
    "#Logistic regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Obtain the performance measure - accuracy\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "#Show results\n",
    "print(f'Logistic regression TOP10, k-fold {splits:d} - Accuracy {results.mean()*100:5.3f}% ({results.std()*100:5.3f}%)')\n",
    "\n",
    "print('-----------------------------K-FOLD TOP50------------------------------------')\n",
    "\n",
    "# Select input and target variables and transform to numpy arrays.\n",
    "X = pd.concat([times.iloc[:,3:11],times['females']],axis=1).values\n",
    "times['Top50'] = times['world_rank']<51\n",
    "Y = times['Top50'].values\n",
    "\n",
    "# Imports (although not necessary because I have imported them already above, to remember)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# KFold\n",
    "splits=10\n",
    "kfold=KFold(n_splits=splits, random_state=7)\n",
    "\n",
    "#Logistic regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Obtain the performance measure - accuracy\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "#Show results\n",
    "print(f'Logistic regression TOP50, k-fold {splits:d} - Accuracy {results.mean()*100:5.3f}% ({results.std()*100:5.3f}%)')\n",
    "\n",
    "print('-----------------------------K-FOLD TOP100------------------------------------')\n",
    "\n",
    "# Select input and target variables and transform to numpy arrays.\n",
    "X = pd.concat([times.iloc[:,3:11],times['females']],axis=1).values\n",
    "times['Top100'] = times['world_rank']<101\n",
    "Y = times['Top100'].values\n",
    "\n",
    "# Imports (although not necessary because I have imported them already above, to remember)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# KFold\n",
    "splits=10\n",
    "kfold=KFold(n_splits=splits, random_state=7)\n",
    "\n",
    "#Logistic regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Obtain the performance measure - accuracy\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "#Show results\n",
    "print(f'Logistic regression TOP100, k-fold {splits:d} - Accuracy {results.mean()*100:5.3f}% ({results.std()*100:5.3f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world_rank</th>\n",
       "      <th>university_name</th>\n",
       "      <th>country</th>\n",
       "      <th>teaching</th>\n",
       "      <th>international</th>\n",
       "      <th>research</th>\n",
       "      <th>citations</th>\n",
       "      <th>income</th>\n",
       "      <th>num_students</th>\n",
       "      <th>student_staff_ratio</th>\n",
       "      <th>international_students</th>\n",
       "      <th>female_male_ratio</th>\n",
       "      <th>year</th>\n",
       "      <th>females</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>California Institute of Technology</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>97.7</td>\n",
       "      <td>54.6</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>83.7</td>\n",
       "      <td>2243.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.27</td>\n",
       "      <td>33 : 67</td>\n",
       "      <td>2011</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>97.8</td>\n",
       "      <td>82.3</td>\n",
       "      <td>91.4</td>\n",
       "      <td>99.9</td>\n",
       "      <td>87.5</td>\n",
       "      <td>11074.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>37 : 63</td>\n",
       "      <td>2011</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>98.3</td>\n",
       "      <td>29.5</td>\n",
       "      <td>98.1</td>\n",
       "      <td>99.2</td>\n",
       "      <td>64.3</td>\n",
       "      <td>15596.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.22</td>\n",
       "      <td>42 : 58</td>\n",
       "      <td>2011</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>90.5</td>\n",
       "      <td>77.7</td>\n",
       "      <td>94.1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>18812.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>46 : 54</td>\n",
       "      <td>2011</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>University of Oxford</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>88.2</td>\n",
       "      <td>77.2</td>\n",
       "      <td>93.9</td>\n",
       "      <td>95.1</td>\n",
       "      <td>73.5</td>\n",
       "      <td>19919.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.34</td>\n",
       "      <td>46 : 54</td>\n",
       "      <td>2011</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   world_rank                        university_name  \\\n",
       "1         2.0     California Institute of Technology   \n",
       "2         3.0  Massachusetts Institute of Technology   \n",
       "3         4.0                    Stanford University   \n",
       "5         6.0                University of Cambridge   \n",
       "6         6.0                   University of Oxford   \n",
       "\n",
       "                    country  teaching  international  research  citations  \\\n",
       "1  United States of America      97.7           54.6      98.0       99.9   \n",
       "2  United States of America      97.8           82.3      91.4       99.9   \n",
       "3  United States of America      98.3           29.5      98.1       99.2   \n",
       "5            United Kingdom      90.5           77.7      94.1       94.0   \n",
       "6            United Kingdom      88.2           77.2      93.9       95.1   \n",
       "\n",
       "   income  num_students  student_staff_ratio  international_students  \\\n",
       "1    83.7        2243.0                  6.9                    0.27   \n",
       "2    87.5       11074.0                  9.0                    0.33   \n",
       "3    64.3       15596.0                  7.8                    0.22   \n",
       "5    57.0       18812.0                 11.8                    0.34   \n",
       "6    73.5       19919.0                 11.6                    0.34   \n",
       "\n",
       "  female_male_ratio  year  females  \n",
       "1           33 : 67  2011     33.0  \n",
       "2           37 : 63  2011     37.0  \n",
       "3           42 : 58  2011     42.0  \n",
       "5           46 : 54  2011     46.0  \n",
       "6           46 : 54  2011     46.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------Train-test split TOP10------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B) Same for the data of the Times ranking. \n",
    "\n",
    "# I copy-paste the code of my previous notebook.\n",
    "# Import dataset and do corresponding adjustments.\n",
    "times = pd.read_csv('timesData.csv')\n",
    "times.world_rank.replace('=.','.', regex=True, inplace=True)\n",
    "times['world_rank'] = times['world_rank'].str.split('-').str.get(0).astype(float)\n",
    "times.world_rank = pd.to_numeric(times.world_rank, errors='coerce')\n",
    "times.dropna(subset=['world_rank'], axis=0, inplace=True)\n",
    "times.international = pd.to_numeric(times.international, errors='coerce')\n",
    "times.income = pd.to_numeric(times.income, errors='coerce')\n",
    "times.num_students.replace('\\D','', regex=True, inplace=True)\n",
    "times.num_students = pd.to_numeric(times.num_students, errors='coerce')\n",
    "times.international_students.replace('\\D','', regex=True, inplace=True)\n",
    "times.international_students = pd.to_numeric(times.international_students, errors='coerce')\n",
    "times.international_students = times.international_students/100\n",
    "times['females'] = times.female_male_ratio.str.split(':').str.get(0)\n",
    "times.females = pd.to_numeric(times.females, errors='coerce')\n",
    "times.drop(columns='total_score',inplace=True)\n",
    "times.dropna(inplace=True)\n",
    "times.head()\n",
    "\n",
    "\n",
    "print('-----------------------------Train-test split TOP10------------------------------------')\n",
    "\n",
    "# Select input and target variables and transform to numpy arrays.\n",
    "X = pd.concat([times.iloc[:,3:11],times['females']],axis=1).values\n",
    "times['Top10'] = times['world_rank']<11\n",
    "Y = times['Top10'].values\n",
    "\n",
    "\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "test_size=0.3 \n",
    "seed = 7 # to reproduce\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "result = model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
